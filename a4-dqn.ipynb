{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PA4 Part 3: DQN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3szwJAdaoQa"
      },
      "source": [
        "## Enable rendering OpenAI Gym environments from CoLab\n",
        "\n",
        "In this assignemnt, We will use [OpenAI Gym](https://gym.openai.com/) for rendering game envionment for our agent to play and learn. It is possible and important to visualize the game your agent is playing, even on Colab. This section imports the necessary package and functions needed to generate a video in Colab. The video processing steps credit to [here](https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rFaTvFab6Kz"
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9fFfA-gb8oC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2acc75-d26f-4572-805f-dd901c6fd773"
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.7/dist-packages (54.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfTPg6uZckCm"
      },
      "source": [
        "Import openAI gym and define the functions used to show the video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLl9cs6ncAf0"
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHkrflTWakKd"
      },
      "source": [
        "Import other packages:\n",
        "\n",
        "We will use Pytorch for building and learning our DQN network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KvZYSl6RrzD"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import copy\n",
        "from collections import deque\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrLGCk-3ditk"
      },
      "source": [
        "## Run the game with random agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMcGALcWeWfh"
      },
      "source": [
        "from torch import randint\n",
        "from time import sleep\n",
        "\n",
        "env = wrap_env(gym.make('CartPole-v0'))\n",
        "reward_arr = []\n",
        "episode_count = 20\n",
        "for i in tqdm(range(episode_count)):\n",
        "    obs, done, rew = env.reset(), False, 0\n",
        "    env.render()\n",
        "    while not done:\n",
        "        A = randint(0, env.action_space.n, (1,))\n",
        "        obs, reward, done, info = env.step(A.item())\n",
        "        rew += reward\n",
        "        sleep(0.01)\n",
        "    reward_arr.append(rew)\n",
        "print(\"average reward per episode :\", sum(reward_arr) / len(reward_arr))\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ope0zHAjfXQh"
      },
      "source": [
        "You can see that a random agent is having trouble balancing the CartPole, just like you. However, a difficult game for human may be very simple to a computer. Let's see how we can use DQN to train a agent. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjP_2jn3SFgv"
      },
      "source": [
        "## Experience Replay\n",
        "\n",
        "The technique of experience replay was first proposed in to resolve temporal correlation in the input data by mixing recent experiences as well past experiences, essentially forcing the input to become independent and identically distributed (i.i.d.). It has been shown that this greatly stabilizes\n",
        "and improves the DQN training procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoxW1Jlnk8mS"
      },
      "source": [
        "class ExperienceReplay(object):\n",
        "      def __init__(self, length):\n",
        "        self.experience_replay = deque(maxlen=length)\n",
        "\n",
        "      def collect(self, experience):\n",
        "        self.experience_replay.append(experience)\n",
        "        return\n",
        "\n",
        "      def sample_from_experience(self, sample_size):\n",
        "        if len(self.experience_replay) < sample_size:\n",
        "            sample_size = len(self.experience_replay)\n",
        "        sample = random.sample(self.experience_replay, sample_size)\n",
        "        state = torch.tensor([exp[0] for exp in sample]).float()\n",
        "        action = torch.tensor([exp[1] for exp in sample]).float()\n",
        "        reward = torch.tensor([exp[2] for exp in sample]).float()\n",
        "        next_state = torch.tensor([exp[3] for exp in sample]).float()\n",
        "        return state, action, reward, next_state\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgXwmV2im4Sx"
      },
      "source": [
        "## Build our DQN Network\n",
        "\n",
        "We will use a simple multi-layer neural network to learn the optimal actions. We will use Adam Optimizor and MSE loss for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmd1pfuRm7MQ"
      },
      "source": [
        "class DQN_Network:\n",
        "\n",
        "    def __init__(self, layer_size_list, lr, seed=1423):\n",
        "        torch.manual_seed(seed)\n",
        "        self.policy_net = self.create_network(layer_size_list)\n",
        "        self.target_net = copy.deepcopy(self.policy_net)\n",
        "  \n",
        "        self.loss_fn = torch.nn.MSELoss()\n",
        "        self.optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=lr)\n",
        "\n",
        "        self.step = 0\n",
        "        self.gamma = torch.tensor(0.95).float()\n",
        "        return\n",
        "\n",
        "    def create_network(self, layer_size_list):\n",
        "        assert len(layer_size_list) > 1\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(layer_size_list) - 1):\n",
        "            linear = nn.Linear(layer_size_list[i], layer_size_list[i + 1])\n",
        "\n",
        "            if i < len(layer_size_list) - 2:\n",
        "              activation = nn.Tanh()\n",
        "            else:\n",
        "              activation = nn.Identity()\n",
        "\n",
        "            layers += (linear, activation)\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def load_pretrained_model(self, model_path):\n",
        "        self.policy_net.load_state_dict(torch.load(model_path))\n",
        "\n",
        "    def save_trained_model(self, model_path=\"cartpole-dqn.pth\"):\n",
        "        torch.save(self.policy_net.state_dict(), model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKVV16YctASm"
      },
      "source": [
        "## **[Your task]**: complete the function that chooses the next action\n",
        "\n",
        "Choose next action based on **$\\epsilon$-greedy**:\n",
        "\n",
        "\\begin{align}\\text{where} \\quad \\mathcal{a_{t+1}} = \\begin{cases}\n",
        "     \\text{argmax}_{a}Q(a, s)  & \\text{with probability }: 1 - \\epsilon, \\text{exploitation}\\\\\n",
        "     \\text{Uniform}\\{a_{1},...,a_{n}\\} & \\text{with probability}:   \\epsilon, \\text{exploration} \\\\\n",
        "   \\end{cases}\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE0gVweYs8xW"
      },
      "source": [
        "def get_action(model, state, action_space_len, epsilon):\n",
        "    # We do not require gradient at this point, because this function will be used either\n",
        "    # during experience collection or during inference\n",
        "\n",
        "    with torch.no_grad():\n",
        "        Qp = model.policy_net(torch.from_numpy(state).float())\n",
        "    Q_value, action = torch.max(Qp, axis=0)\n",
        "\n",
        "    ## TODO: select action and action\n",
        "    if (np.random.random() < epsilon):\n",
        "      action = randint(0, env.action_space.n, (1,))\n",
        "      return action\n",
        "    return action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF9a5-IbazjQ"
      },
      "source": [
        "### **[Your task]**: complete the function that train the network for one step\n",
        "\n",
        "Here, you can find an ``train`` function that performs a\n",
        "single step of the optimization. \n",
        "\n",
        "For our training update rule, the loss you are trying to minimize is:\n",
        "\n",
        "\\begin{align}\\text{loss} = Q(s, a) - (r + \\gamma \\max_a Q(s', a))\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtx4FAiab0Hp"
      },
      "source": [
        "def train(model, batch_size):\n",
        "    state, action, reward, next_state = memory.sample_from_experience(sample_size=batch_size)\n",
        "    # TODO: predict expected return of current state using main network\n",
        "    \n",
        "    exp_ret = model.policy_net(state).gather(1, action.unsqueeze(1).long()).squeeze()\n",
        "\n",
        "\n",
        "    # TODO: get target return using target network\n",
        "    \n",
        "    target_ret = model.target_net(next_state).max(1)[0]\n",
        "\n",
        "\n",
        "    # TODO: compute the loss\n",
        "    r = reward + model.gamma * target_ret\n",
        "    loss = model.loss_fn(exp_ret, r)\n",
        "    \n",
        "    model.optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    model.optimizer.step()\n",
        "\n",
        "    model.step += 1\n",
        "    if model.step % 5 == 0:\n",
        "        model.target_net.load_state_dict(model.policy_net.state_dict())\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uskoe87Uz-Jg"
      },
      "source": [
        "### **[Your task]**: Finish the training loop\n",
        "\n",
        "In this part, you can play around with ```exp_replay_size```, ```episode```, ```epsilon``` and the \"episodo decay\" logic to train your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NfNnyD6SPpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7371a06c-a6ed-4351-e1fd-97123815275f"
      },
      "source": [
        "import numpy as np\n",
        "# Create the model\n",
        "env = gym.make('CartPole-v0')\n",
        "input_dim = env.observation_space.shape[0]\n",
        "output_dim = env.action_space.n\n",
        "agent = DQN_Network(layer_size_list=[input_dim, 64, output_dim], lr=1e-3)\n",
        "\n",
        "# Main training loop\n",
        "losses_list, reward_list, episode_len_list, epsilon_list = [], [], [], []\n",
        "\n",
        "# TODO: try different values, it normally takes more than 6k episodes to train\n",
        "exp_replay_size = 200\n",
        "memory = ExperienceReplay(exp_replay_size)\n",
        "episodes = 10000\n",
        "epsilon = 1 # episilon start from 1 and decay gradually. \n",
        "\n",
        "# initiliaze experiance replay\n",
        "index = 0\n",
        "for i in range(exp_replay_size):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        A = get_action(agent, obs, env.action_space.n, epsilon=1)\n",
        "        obs_next, reward, done, _ = env.step(A.item())\n",
        "        memory.collect([obs, A.item(), reward, obs_next])\n",
        "        obs = obs_next\n",
        "        index += 1\n",
        "        if index > exp_replay_size:\n",
        "            break\n",
        "\n",
        "index = 128\n",
        "for i in tqdm(range(episodes)):\n",
        "    obs, done, losses, ep_len, rew = env.reset(), False, 0, 0, 0\n",
        "    while not done:\n",
        "        ep_len += 1\n",
        "        A = get_action(agent, obs, env.action_space.n, epsilon)\n",
        "        obs_next, reward, done, _ = env.step(A.item())\n",
        "        memory.collect([obs, A.item(), reward, obs_next])\n",
        "\n",
        "        obs = obs_next\n",
        "        rew += reward\n",
        "        index += 1\n",
        "\n",
        "        if index > 128:\n",
        "            index = 0\n",
        "            for j in range(4):\n",
        "                loss = train(agent, batch_size=16)\n",
        "                losses += loss\n",
        "    \n",
        "    # TODO: add epsilon decay rule here! \n",
        "\n",
        "    epsilon *= 0.999\n",
        "\n",
        "    losses_list.append(losses / ep_len), reward_list.append(rew)\n",
        "    episode_len_list.append(ep_len), epsilon_list.append(epsilon)\n",
        "\n",
        "print(\"Saving trained model\")\n",
        "agent.save_trained_model(\"cartpole-dqn.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [01:59<00:00, 83.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving trained model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCow7jNXf5YT"
      },
      "source": [
        "## Last Step: evaluate your trained model!\n",
        "\n",
        "First we can plot the reward vs. episode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hy_FP7yeXA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f1d5d800-33cb-4e8f-9bb4-631c4c8cf13c"
      },
      "source": [
        "def plot_reward(r):\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    plt.title('Result')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.plot(r)\n",
        "\n",
        "plot_reward(reward_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMEivKldTGVG"
      },
      "source": [
        "env = wrap_env(gym.make('CartPole-v0'))\n",
        "\n",
        "input_dim = env.observation_space.shape[0]\n",
        "output_dim = env.action_space.n\n",
        "model_validate = DQN_Network(layer_size_list=[input_dim, 64, output_dim], lr=1e-3)\n",
        "model_validate.load_pretrained_model(\"cartpole-dqn.pth\")\n",
        "\n",
        "reward_arr = []\n",
        "for i in tqdm(range(300)):\n",
        "    obs, done, rew = env.reset(), False, 0\n",
        "    env.render()\n",
        "    while not done:\n",
        "        A = get_action(model_validate, obs, env.action_space.n, epsilon=0)\n",
        "        obs, reward, done, info = env.step(A.item())\n",
        "        rew += reward\n",
        "        # sleep(0.01)\n",
        "\n",
        "    reward_arr.append(rew)\n",
        "print(\"average reward per episode :\", sum(reward_arr) / len(reward_arr))\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}