{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjPTaRB4mpCd"
   },
   "source": [
    "# Colab FAQ\n",
    "\n",
    "For some basic overview and features offered in Colab notebooks, check out: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
    "\n",
    "You need to use the colab GPU for this assignmentby selecting:\n",
    "\n",
    "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9IS9B9-yUU5"
   },
   "source": [
    "## Setup PyTorch\n",
    "All files are stored at /content/csc421/a3/ folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axbuunY8UdTB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "Z-6MQhMOlHXD",
    "outputId": "f7620ac1-82ef-4854-ea4c-ad9aa83f015e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0+cu101)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.0+cu101)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.0.0)\n",
      "Collecting Pillow==4.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/80/eca7a2d1a3c2dafb960f32f844d570de988e609f5fd17de92e1cf6a01b0a/Pillow-4.0.0.tar.gz (11.1MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1MB 8.1MB/s \n",
      "\u001b[?25hCollecting olefile\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 50.9MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: Pillow, olefile\n",
      "  Building wheel for Pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Pillow: filename=Pillow-4.0.0-cp37-cp37m-linux_x86_64.whl size=1007179 sha256=a1e95c298c4347876fec0e93be6d1ce9376520d00de3e2892ab5e72ba8def6f1\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/0a/2a/7e3391063af230fac4b5fdb4cc93adcb1d99af325b623cea03\n",
      "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35416 sha256=9843847187e2ed984f975d55ed79c876191386c88bd3df4592c1819656d992fe\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n",
      "Successfully built Pillow olefile\n",
      "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: scikit-image 0.16.2 has requirement pillow>=4.3.0, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: olefile, Pillow\n",
      "  Found existing installation: Pillow 7.0.0\n",
      "    Uninstalling Pillow-7.0.0:\n",
      "      Successfully uninstalled Pillow-7.0.0\n",
      "Successfully installed Pillow-4.0.0 olefile-0.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/content/csc421/a3\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Setup python environment and change the current working directory\n",
    "######################################################################\n",
    "!pip install torch torchvision\n",
    "!pip install Pillow==4.0.0\n",
    "%mkdir -p ./content/csc421/a3/\n",
    "%cd ./content/csc421/a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DaTdRNuUra7"
   },
   "source": [
    "# Helper code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BIpGwANoQOg"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D-UJHBYZkh7f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "\n",
    "def get_file(fname,\n",
    "             origin,\n",
    "             untar=False,\n",
    "             extract=False,\n",
    "             archive_format='auto',\n",
    "             cache_dir='data'):\n",
    "    datadir = os.path.join(cache_dir)\n",
    "    if not os.path.exists(datadir):\n",
    "        os.makedirs(datadir)\n",
    "\n",
    "    if untar:\n",
    "        untar_fpath = os.path.join(datadir, fname)\n",
    "        fpath = untar_fpath + '.tar.gz'\n",
    "    else:\n",
    "        fpath = os.path.join(datadir, fname)\n",
    "    \n",
    "    print(fpath)\n",
    "    if not os.path.exists(fpath):\n",
    "        print('Downloading data from', origin)\n",
    "\n",
    "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
    "        try:\n",
    "            try:\n",
    "                urlretrieve(origin, fpath)\n",
    "            except URLError as e:\n",
    "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
    "            except HTTPError as e:\n",
    "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
    "        except (Exception, KeyboardInterrupt) as e:\n",
    "            if os.path.exists(fpath):\n",
    "                os.remove(fpath)\n",
    "            raise\n",
    "\n",
    "    if untar:\n",
    "        if not os.path.exists(untar_fpath):\n",
    "            print('Extracting file.')\n",
    "            with tarfile.open(fpath) as archive:\n",
    "                archive.extractall(datadir)\n",
    "        return untar_fpath\n",
    "\n",
    "    if extract:\n",
    "        _extract_archive(fpath, datadir, archive_format)\n",
    "\n",
    "    return fpath\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "def to_var(tensor, cuda):\n",
    "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
    "\n",
    "        Arguments:\n",
    "            tensor: A Tensor object.\n",
    "            cuda: A boolean flag indicating whether to use the GPU.\n",
    "\n",
    "        Returns:\n",
    "            A Variable object, on the GPU if cuda==True.\n",
    "    \"\"\"\n",
    "    if cuda:\n",
    "        return Variable(tensor.cuda())\n",
    "    else:\n",
    "        return Variable(tensor)\n",
    "\n",
    "\n",
    "def create_dir_if_not_exists(directory):\n",
    "    \"\"\"Creates a directory if it doesn't already exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def save_loss_plot(train_losses, val_losses, opts):\n",
    "    \"\"\"Saves a plot of the training and validation loss curves.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses)\n",
    "    plt.plot(range(len(val_losses)), val_losses)\n",
    "    plt.title('BS={}, nhid={}'.format(opts.batch_size, opts.hidden_size), fontsize=20)\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(opts.checkpoint_path, 'loss_plot.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_loss_comparison_lstm(l1, l2, o1, o2, fn, s=500):\n",
    "    \"\"\"Plot comparison of training and val loss curves from LSTM runs.\n",
    "    \n",
    "    Arguments:\n",
    "        l1: Tuple of lists containing training / val losses for model 1.\n",
    "        l2: Tuple of lists containing training / val losses for model 2.\n",
    "        o1: Options for model 1.\n",
    "        o2: Options for model 2.\n",
    "        fn: Output file name.\n",
    "        s: Number of training iterations to average over.\n",
    "    \"\"\"\n",
    "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
    "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    ax[0].plot(range(len(mean_l1)), mean_l1, label='ds=' + o1.data_file_name)\n",
    "    ax[0].plot(range(len(mean_l2)), mean_l2, label='ds=' + o2.data_file_name)\n",
    "    ax[0].title.set_text('Train Loss | LSTM Hidden Size = {}'.format(o2.hidden_size))\n",
    "\n",
    "    # Validation losses are assumed to be by epoch\n",
    "    ax[1].plot(range(len(l1[1])), l1[1], label='ds=' + o1.data_file_name)\n",
    "    ax[1].plot(range(len(l2[1])), l2[1], label='ds=' + o2.data_file_name)\n",
    "    ax[1].title.set_text('Val Loss | LSTM Hidden Size = {}'.format(o2.hidden_size))\n",
    "\n",
    "    ax[0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
    "    ax[0].set_ylabel(\"Loss\", fontsize=10)\n",
    "    ax[1].set_xlabel(\"Epochs\", fontsize=10)\n",
    "    ax[1].set_ylabel(\"Loss\", fontsize=10)\n",
    "    ax[0].legend(loc=\"upper right\")\n",
    "    ax[1].legend(loc=\"upper right\")\n",
    "\n",
    "    fig.suptitle('LSTM Performance by Dataset', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    plt.legend()\n",
    "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_loss_comparison_by_dataset(l1, l2, l3, l4, o1, o2, o3, o4, fn, s=500):\n",
    "    \"\"\"Plot comparison of training and validation loss curves from all four\n",
    "    runs in Part 3, comparing by dataset while holding hidden size constant.\n",
    "\n",
    "    Models within each pair (l1, l2) and (l3, l4) have the same hidden sizes.\n",
    "\n",
    "    Arguments:\n",
    "        l1: Tuple of lists containing training / val losses for model 1.\n",
    "        l2: Tuple of lists containing training / val losses for model 2.\n",
    "        l3: Tuple of lists containing training / val losses for model 3.\n",
    "        l4: Tuple of lists containing training / val losses for model 4.\n",
    "        o1: Options for model 1.\n",
    "        o2: Options for model 2.\n",
    "        o3: Options for model 3.\n",
    "        o4: Options for model 4.\n",
    "        fn: Output file name.\n",
    "        s: Number of training iterations to average over.\n",
    "    \"\"\"\n",
    "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
    "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
    "    mean_l3 = [np.mean(l3[0][i*s:(i+1)*s]) for i in range(len(l3[0]) // s)]\n",
    "    mean_l4 = [np.mean(l4[0][i*s:(i+1)*s]) for i in range(len(l4[0]) // s)]\n",
    "\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "    ax[0][0].plot(range(len(mean_l1)), mean_l1, label='ds=' + o1.data_file_name)\n",
    "    ax[0][0].plot(range(len(mean_l2)), mean_l2, label='ds=' + o2.data_file_name)\n",
    "    ax[0][0].title.set_text('Train Loss | Model Hidden Size = {}'.format(o1.hidden_size))\n",
    "\n",
    "    # Validation losses are assumed to be by epoch\n",
    "    ax[0][1].plot(range(len(l1[1])), l1[1], label='ds=' + o1.data_file_name)\n",
    "    ax[0][1].plot(range(len(l2[1])), l2[1], label='ds=' + o2.data_file_name)\n",
    "    ax[0][1].title.set_text('Val Loss | Model Hidden Size = {}'.format(o1.hidden_size))\n",
    "\n",
    "    ax[1][0].plot(range(len(mean_l3)), mean_l3, label='ds=' + o3.data_file_name)\n",
    "    ax[1][0].plot(range(len(mean_l4)), mean_l4, label='ds=' + o4.data_file_name)\n",
    "    ax[1][0].title.set_text('Train Loss | Model Hidden Size = {}'.format(o3.hidden_size))\n",
    "\n",
    "    ax[1][1].plot(range(len(l3[1])), l3[1], label='ds=' + o3.data_file_name)\n",
    "    ax[1][1].plot(range(len(l4[1])), l4[1], label='ds=' + o4.data_file_name)\n",
    "    ax[1][1].title.set_text('Val Loss | Model Hidden Size = {}'.format(o4.hidden_size))\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[i][0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
    "        ax[i][0].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][1].set_xlabel(\"Epochs\", fontsize=10)\n",
    "        ax[i][1].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][0].legend(loc=\"upper right\")\n",
    "        ax[i][1].legend(loc=\"upper right\")\n",
    "\n",
    "    fig.suptitle(\"Performance by Dataset Size\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    plt.legend()\n",
    "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
    "    plt.close()\n",
    "\n",
    "def save_loss_comparison_by_hidden(l1, l2, l3, l4, o1, o2, o3, o4, fn, s=500):\n",
    "    \"\"\"Plot comparison of training and validation loss curves from all four\n",
    "    runs in Part 3, comparing by hidden size while holding dataset constant.\n",
    "\n",
    "    Models within each pair (l1, l3) and (l2, l4) have the same dataset.\n",
    "\n",
    "    Arguments:\n",
    "        l1: Tuple of lists containing training / val losses for model 1.\n",
    "        l2: Tuple of lists containing training / val losses for model 2.\n",
    "        l3: Tuple of lists containing training / val losses for model 3.\n",
    "        l4: Tuple of lists containing training / val losses for model 4.\n",
    "        o1: Options for model 1.\n",
    "        o2: Options for model 2.\n",
    "        o3: Options for model 3.\n",
    "        o4: Options for model 4.\n",
    "        fn: Output file name.\n",
    "        s: Number of training iterations to average over.\n",
    "    \"\"\"\n",
    "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
    "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
    "    mean_l3 = [np.mean(l3[0][i*s:(i+1)*s]) for i in range(len(l3[0]) // s)]\n",
    "    mean_l4 = [np.mean(l4[0][i*s:(i+1)*s]) for i in range(len(l4[0]) // s)]\n",
    "\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "    ax[0][0].plot(range(len(mean_l1)), mean_l1, label='hid_size=' + str(o1.hidden_size))\n",
    "    ax[0][0].plot(range(len(mean_l3)), mean_l3, label='hid_size=' + str(o3.hidden_size))\n",
    "    ax[0][0].title.set_text('Train Loss | Dataset = ' + o1.data_file_name)\n",
    "\n",
    "    # Validation losses are assumed to be by epoch\n",
    "    ax[0][1].plot(range(len(l1[1])), l1[1], label='hid_size=' + str(o1.hidden_size))\n",
    "    ax[0][1].plot(range(len(l3[1])), l3[1], label='hid_size=' + str(o3.hidden_size))\n",
    "    ax[0][1].title.set_text('Val Loss | Dataset = ' + o1.data_file_name)\n",
    "\n",
    "    ax[1][0].plot(range(len(mean_l2)), mean_l2, label='hid_size=' + str(o2.hidden_size))\n",
    "    ax[1][0].plot(range(len(mean_l4)), mean_l4, label='hid_size=' + str(o4.hidden_size))\n",
    "    ax[1][0].title.set_text('Train Loss | Dataset = ' + o3.data_file_name)\n",
    "\n",
    "    ax[1][1].plot(range(len(l2[1])), l2[1], label='hid_size=' + str(o2.hidden_size))\n",
    "    ax[1][1].plot(range(len(l4[1])), l4[1], label='hid_size=' + str(o4.hidden_size))\n",
    "    ax[1][1].title.set_text('Val Loss | Dataset = ' + o4.data_file_name)\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[i][0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
    "        ax[i][0].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][1].set_xlabel(\"Epochs\", fontsize=10)\n",
    "        ax[i][1].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][0].legend(loc=\"upper right\")\n",
    "        ax[i][1].legend(loc=\"upper right\")\n",
    "\n",
    "    fig.suptitle(\"Performance by Hidden State Size\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    plt.legend()\n",
    "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def checkpoint(encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Saves the current encoder and decoder models, along with idx_dict, which\n",
    "    contains the char_to_index and index_to_char mappings, and the start_token\n",
    "    and end_token values.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(opts.checkpoint_path, 'encoder.pt'), 'wb') as f:\n",
    "        torch.save(encoder, f)\n",
    "\n",
    "    with open(os.path.join(opts.checkpoint_path, 'decoder.pt'), 'wb') as f:\n",
    "        torch.save(decoder, f)\n",
    "\n",
    "    with open(os.path.join(opts.checkpoint_path, 'idx_dict.pkl'), 'wb') as f:\n",
    "        pkl.dump(idx_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbvpn4MaV0I1"
   },
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XVT4TNTOV3Eg"
   },
   "outputs": [],
   "source": [
    "def read_lines(filename):\n",
    "    \"\"\"Read a file and split it into lines.\n",
    "    \"\"\"\n",
    "    lines = open(filename).read().strip().lower().split('\\n')\n",
    "    return lines\n",
    "\n",
    "\n",
    "def read_pairs(filename):\n",
    "    \"\"\"Reads lines that consist of two words, separated by a space.\n",
    "\n",
    "    Returns:\n",
    "        source_words: A list of the first word in each line of the file.\n",
    "        target_words: A list of the second word in each line of the file.\n",
    "    \"\"\"\n",
    "    lines = read_lines(filename)\n",
    "    source_words, target_words = [], []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            source, target = line.split()\n",
    "            source_words.append(source)\n",
    "            target_words.append(target)\n",
    "    return source_words, target_words\n",
    "\n",
    "\n",
    "def all_alpha_or_dash(s):\n",
    "    \"\"\"Helper function to check whether a string is alphabetic, allowing dashes '-'.\n",
    "    \"\"\"\n",
    "    return all(c.isalpha() or c == '-' for c in s)\n",
    "\n",
    "\n",
    "def filter_lines(lines):\n",
    "    \"\"\"Filters lines to consist of only alphabetic characters or dashes \"-\".\n",
    "    \"\"\"\n",
    "    return [line for line in lines if all_alpha_or_dash(line)]\n",
    "\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"Loads (English, Pig-Latin) word pairs, and creates mappings from characters to indexes.\n",
    "    \"\"\"\n",
    "    path = \"./data/{}.txt\".format(file_name)\n",
    "    source_lines, target_lines = read_pairs(path)\n",
    "\n",
    "    # Filter lines\n",
    "    source_lines = filter_lines(source_lines)\n",
    "    target_lines = filter_lines(target_lines)\n",
    "\n",
    "    all_characters = set(''.join(source_lines)) | set(''.join(target_lines))\n",
    "\n",
    "    # Create a dictionary mapping each character to a unique index\n",
    "    char_to_index = { char: index for (index, char) in enumerate(sorted(list(all_characters))) }\n",
    "\n",
    "    # Add start and end tokens to the dictionary\n",
    "    start_token = len(char_to_index)\n",
    "    end_token = len(char_to_index) + 1\n",
    "    char_to_index['SOS'] = start_token\n",
    "    char_to_index['EOS'] = end_token\n",
    "\n",
    "    # Create the inverse mapping, from indexes to characters (used to decode the model's predictions)\n",
    "    index_to_char = { index: char for (char, index) in char_to_index.items() }\n",
    "\n",
    "    # Store the final size of the vocabulary\n",
    "    vocab_size = len(char_to_index)\n",
    "\n",
    "    line_pairs = list(set(zip(source_lines, target_lines)))  # Python 3\n",
    "\n",
    "    idx_dict = { 'char_to_index': char_to_index,\n",
    "                 'index_to_char': index_to_char,\n",
    "                 'start_token': start_token,\n",
    "                 'end_token': end_token }\n",
    "\n",
    "    return line_pairs, vocab_size, idx_dict\n",
    "\n",
    "\n",
    "def create_dict(pairs):\n",
    "    \"\"\"Creates a mapping { (source_length, target_length): [list of (source, target) pairs]\n",
    "    This is used to make batches: each batch consists of two parallel tensors, one containing\n",
    "    all source indexes and the other containing all corresponding target indexes.\n",
    "    Within a batch, all the source words are the same length, and all the target words are\n",
    "    the same length.\n",
    "    \"\"\"\n",
    "    unique_pairs = list(set(pairs))  # Find all unique (source, target) pairs\n",
    "\n",
    "    d = defaultdict(list)\n",
    "    for (s,t) in unique_pairs:\n",
    "        d[(len(s), len(t))].append((s,t))\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRWfRdmVVjUl"
   },
   "source": [
    "## Training and evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wa5-onJhoSeM"
   },
   "outputs": [],
   "source": [
    "def string_to_index_list(s, char_to_index, end_token):\n",
    "    \"\"\"Converts a sentence into a list of indexes (for each character).\n",
    "    \"\"\"\n",
    "    return [char_to_index[char] for char in s] + [end_token]  # Adds the end token to each index list\n",
    "\n",
    "\n",
    "def translate_sentence(sentence, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
    "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
    "    word independently, and then stitching the words back together with spaces between them.\n",
    "    \"\"\"\n",
    "    if idx_dict is None:\n",
    "      line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
    "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
    "\n",
    "\n",
    "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a given string from English to Pig-Latin.\n",
    "    \"\"\"\n",
    "\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "\n",
    "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
    "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
    "\n",
    "    encoder_annotations, encoder_last_hidden, encoder_last_cell = encoder(indexes)\n",
    "\n",
    "    decoder_hidden = encoder_last_hidden\n",
    "    decoder_cell = encoder_last_cell\n",
    "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
    "    decoder_inputs = decoder_input\n",
    "\n",
    "    for i in range(max_generated_chars):\n",
    "        ## slow decoding, recompute everything at each time\n",
    "        decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
    "\n",
    "        generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
    "        ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
    "        ni = ni[-1] #latest output token\n",
    "\n",
    "        decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
    "\n",
    "        if ni == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string = \"\".join(\n",
    "                [index_to_char[int(item)] \n",
    "                for item in generated_words.cpu().numpy().reshape(-1)])\n",
    "\n",
    "    return gen_string\n",
    "\n",
    "\n",
    "def visualize_attention(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Generates a heatmap to show where attention is focused in each decoder step.\n",
    "    \"\"\"\n",
    "    if idx_dict is None:\n",
    "      line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "\n",
    "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
    "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
    "\n",
    "    encoder_annotations, encoder_hidden, encoder_cell = encoder(indexes)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell = encoder_cell\n",
    "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
    "    decoder_inputs = decoder_input\n",
    "\n",
    "    produced_end_token = False\n",
    "\n",
    "    for i in range(max_generated_chars):\n",
    "        ## slow decoding, recompute everything at each time\n",
    "        decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
    "        generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
    "        ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
    "        ni = ni[-1] #latest output token\n",
    "\n",
    "        decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
    "\n",
    "        if ni == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string = \"\".join(\n",
    "                [index_to_char[int(item)] \n",
    "                for item in generated_words.cpu().numpy().reshape(-1)])\n",
    "    \n",
    "    if isinstance(attention_weights, tuple):\n",
    "      ## transformer's attention mweights\n",
    "      attention_weights, self_attention_weights = attention_weights\n",
    "    \n",
    "    all_attention_weights = attention_weights.data.cpu().numpy()\n",
    "    \n",
    "    for i in range(len(all_attention_weights)):\n",
    "        attention_weights_matrix = all_attention_weights[i].squeeze()\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(attention_weights_matrix, cmap='bone')\n",
    "        fig.colorbar(cax)\n",
    "\n",
    "        # Set up axes\n",
    "        ax.set_yticklabels([''] + list(input_string) + ['EOS'], rotation=90)\n",
    "        ax.set_xticklabels([''] + list(gen_string) + (['EOS'] if produced_end_token else []))\n",
    "\n",
    "        # Show label at every tick\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        # Add title\n",
    "        plt.xlabel('Attention weights to the source sentence in layer {}'.format(i+1))\n",
    "        plt.tight_layout()\n",
    "        plt.grid('off')\n",
    "        plt.show()\n",
    "\n",
    "    return gen_string\n",
    "\n",
    "\n",
    "def compute_loss(data_dict, encoder, decoder, idx_dict, criterion, optimizer, opts):\n",
    "    \"\"\"Train/Evaluate the model on a dataset.\n",
    "\n",
    "    Arguments:\n",
    "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        optimizer: Train the weights if an optimizer is given. None if only evaluate the model. \n",
    "        opts: The command-line arguments.\n",
    "\n",
    "    Returns:\n",
    "        mean_loss: The average loss over all batches from data_dict.\n",
    "    \"\"\"\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    losses = []\n",
    "    for key in data_dict:\n",
    "        input_strings, target_strings = zip(*data_dict[key])\n",
    "        input_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in input_strings]\n",
    "        target_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in target_strings]\n",
    "\n",
    "        num_tensors = len(input_tensors)\n",
    "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "\n",
    "        for i in range(num_batches):\n",
    "\n",
    "            start = i * opts.batch_size\n",
    "            end = start + opts.batch_size\n",
    "\n",
    "            inputs = to_var(torch.stack(input_tensors[start:end]), opts.cuda)\n",
    "            targets = to_var(torch.stack(target_tensors[start:end]), opts.cuda)\n",
    "\n",
    "            # The batch size may be different in each epoch\n",
    "            BS = inputs.size(0)\n",
    "\n",
    "            encoder_annotations, encoder_hidden, encoder_cell = encoder(inputs)\n",
    "\n",
    "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "            decoder_hidden = encoder_hidden\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "            start_vector = torch.ones(BS).long().unsqueeze(1) * start_token  # BS x 1 --> 16x1  CHECKED\n",
    "            decoder_input = to_var(start_vector, opts.cuda)  # BS x 1 --> 16x1  CHECKED\n",
    "\n",
    "            loss = 0.0\n",
    "\n",
    "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
    "\n",
    "            decoder_inputs = torch.cat([decoder_input, targets[:, 0:-1]], dim=1)  # Gets decoder inputs by shifting the targets to the right \n",
    "\n",
    "            decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
    "            decoder_outputs_flatten = decoder_outputs.view(-1, decoder_outputs.size(2))\n",
    "            targets_flatten = targets.view(-1)\n",
    "            \n",
    "            loss = criterion(decoder_outputs_flatten, targets_flatten)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            ## training if an optimizer is provided\n",
    "            if optimizer:\n",
    "              # Zero gradients\n",
    "              optimizer.zero_grad()\n",
    "              # Compute gradients\n",
    "              loss.backward()\n",
    "              # Update the parameters of the encoder and decoder\n",
    "              optimizer.step()\n",
    "\n",
    "    return losses\n",
    "\n",
    "  \n",
    "\n",
    "def training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts):\n",
    "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
    "        * Prints training and val loss each epoch.\n",
    "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
    "        * Saves an attention map for TEST_WORD_ATTN each epoch\n",
    "        * Returns loss curves for comparison\n",
    "\n",
    "    Arguments:\n",
    "        train_dict: The training word pairs, organized by source and target lengths.\n",
    "        val_dict: The validation word pairs, organized by source and target lengths.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        optimizer: Implements a step rule to update the parameters of the encoder and decoder.\n",
    "        opts: The command-line arguments.\n",
    "    \n",
    "    Returns:\n",
    "        losses: Lists containing training and validation loss curves.\n",
    "    \"\"\"\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    loss_log = open(os.path.join(opts.checkpoint_path, 'loss_log.txt'), 'w')\n",
    "\n",
    "    best_val_loss = 1e6\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    mean_train_losses = []\n",
    "    mean_val_losses = []\n",
    "\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    for epoch in range(opts.nepochs):\n",
    "\n",
    "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "        \n",
    "        train_loss = compute_loss(train_dict, encoder, decoder, idx_dict, criterion, optimizer, opts)\n",
    "        val_loss = compute_loss(val_dict, encoder, decoder, idx_dict, criterion, None, opts)\n",
    "\n",
    "        mean_train_loss = np.mean(train_loss)\n",
    "        mean_val_loss = np.mean(val_loss)\n",
    "\n",
    "        if mean_val_loss < best_val_loss:\n",
    "            checkpoint(encoder, decoder, idx_dict, opts)\n",
    "            best_val_loss = mean_val_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        if early_stopping_counter > opts.early_stopping_patience:\n",
    "            print(\"Validation loss has not improved in {} epochs, stopping early\".format(opts.early_stopping_patience))\n",
    "            print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
    "            return (train_losses, mean_val_losses)\n",
    "\n",
    "        gen_string = translate_sentence(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
    "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, mean_train_loss, mean_val_loss, gen_string))\n",
    "\n",
    "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
    "        loss_log.flush()\n",
    "\n",
    "        train_losses += train_loss\n",
    "        val_losses += val_loss\n",
    "\n",
    "        mean_train_losses.append(mean_train_loss)\n",
    "        mean_val_losses.append(mean_val_loss)\n",
    "\n",
    "        save_loss_plot(mean_train_losses, mean_val_losses, opts)\n",
    "\n",
    "    print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
    "    return (train_losses, mean_val_losses)\n",
    "\n",
    "\n",
    "def print_data_stats(line_pairs, vocab_size, idx_dict):\n",
    "    \"\"\"Prints example word pairs, the number of data points, and the vocabulary.\n",
    "    \"\"\"\n",
    "    print('=' * 80)\n",
    "    print('Data Stats'.center(80))\n",
    "    print('-' * 80)\n",
    "    for pair in line_pairs[:5]:\n",
    "        print(pair)\n",
    "    print('Num unique word pairs: {}'.format(len(line_pairs)))\n",
    "    print('Vocabulary: {}'.format(idx_dict['char_to_index'].keys()))\n",
    "    print('Vocab size: {}'.format(vocab_size))\n",
    "    print('=' * 80)\n",
    "\n",
    "\n",
    "def train(opts):\n",
    "    line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
    "    print_data_stats(line_pairs, vocab_size, idx_dict)\n",
    "\n",
    "    # Split the line pairs into an 80% train and 20% val split\n",
    "    num_lines = len(line_pairs)\n",
    "    num_train = int(0.8 * num_lines)\n",
    "    train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
    "\n",
    "    # Group the data by the lengths of the source and target words, to form batches\n",
    "    train_dict = create_dict(train_pairs)\n",
    "    val_dict = create_dict(val_pairs)\n",
    "\n",
    "    ##########################################################################\n",
    "    ### Setup: Create Encoder, Decoder, Learning Criterion, and Optimizers ###\n",
    "    ##########################################################################\n",
    "    if opts.encoder_type == \"rnn\":\n",
    "        encoder = LSTMEncoder(vocab_size=vocab_size, \n",
    "                              hidden_size=opts.hidden_size, \n",
    "                              opts=opts)\n",
    "    elif opts.encoder_type == \"transformer\":\n",
    "        encoder = TransformerEncoder(vocab_size=vocab_size, \n",
    "                                     hidden_size=opts.hidden_size, \n",
    "                                     num_layers=opts.num_transformer_layers,\n",
    "                                     opts=opts)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if opts.decoder_type == 'rnn':\n",
    "        decoder = RNNDecoder(vocab_size=vocab_size, \n",
    "                             hidden_size=opts.hidden_size)\n",
    "    elif opts.decoder_type == 'rnn_attention':\n",
    "        decoder = RNNAttentionDecoder(vocab_size=vocab_size, \n",
    "                                      hidden_size=opts.hidden_size, \n",
    "                                      attention_type=opts.attention_type)\n",
    "    elif opts.decoder_type == 'transformer':\n",
    "        decoder = TransformerDecoder(vocab_size=vocab_size, \n",
    "                                     hidden_size=opts.hidden_size, \n",
    "                                     num_layers=opts.num_transformer_layers)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    #### setup checkpoint path\n",
    "    model_name = 'h{}-bs{}-{}-{}'.format(opts.hidden_size, \n",
    "                                      opts.batch_size, \n",
    "                                      opts.decoder_type,\n",
    "                                      opts.data_file_name)\n",
    "    opts.checkpoint_path = model_name\n",
    "    create_dir_if_not_exists(opts.checkpoint_path)\n",
    "    ####\n",
    "\n",
    "    if opts.cuda:\n",
    "        encoder.cuda()\n",
    "        decoder.cuda()\n",
    "        print(\"Moved models to GPU!\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=opts.learning_rate)\n",
    "\n",
    "    try:\n",
    "        losses = training_loop(train_dict, val_dict, idx_dict, encoder, \n",
    "                               decoder, criterion, optimizer, opts)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exiting early from training.')\n",
    "        return encoder, decoder, losses\n",
    "      \n",
    "    return encoder, decoder, losses\n",
    "\n",
    "\n",
    "def print_opts(opts):\n",
    "    \"\"\"Prints the values of all command-line arguments.\n",
    "    \"\"\"\n",
    "    print('=' * 80)\n",
    "    print('Opts'.center(80))\n",
    "    print('-' * 80)\n",
    "    for key in opts.__dict__:\n",
    "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
    "    print('=' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yh08KhgnA30"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aROU2xZanDKq",
    "outputId": "f428328c-eaa0-4db6-8b30-5cd88d57f038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pig_latin_small.txt\n",
      "Downloading data from http://www.cs.toronto.edu/~jba/pig_latin_small.txt\n",
      "data/pig_latin_large.txt\n",
      "Downloading data from http://www.cs.toronto.edu/~jba/pig_latin_large.txt\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Download Translation datasets\n",
    "######################################################################\n",
    "data_fpath = get_file(fname='pig_latin_small.txt', \n",
    "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_small.txt', \n",
    "                         untar=False)\n",
    "\n",
    "data_fpath = get_file(fname='pig_latin_large.txt', \n",
    "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_large.txt', \n",
    "                         untar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDYMr7NclZdw"
   },
   "source": [
    "# Part 1: Long Short-Term Memory Unit (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCae1mOUlZrC"
   },
   "source": [
    "## Step 1: LSTM Cell\n",
    "Please implement the Long Short-Term Memory class defined in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cOnALRQkkjDO"
   },
   "outputs": [],
   "source": [
    "class MyLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MyLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # ------------\n",
    "        # FILL THIS IN\n",
    "        # ------------\n",
    "        self.Wii = nn.Linear(input_size, hidden_size)\n",
    "        self.Whi = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.Wif = nn.Linear(input_size, hidden_size)\n",
    "        self.Whf = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.Wig = nn.Linear(input_size, hidden_size)\n",
    "        self.Whg = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.Wio = nn.Linear(input_size, hidden_size)\n",
    "        self.Who = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        \"\"\"Forward pass of the LSTM computation for one time step.\n",
    "\n",
    "        Arguments\n",
    "            x: batch_size x input_size\n",
    "            h_prev: batch_size x hidden_size\n",
    "            c_prev: batch_size x hidden_size\n",
    "\n",
    "        Returns:\n",
    "            h_new: batch_size x hidden_size\n",
    "            c_new: batch_size x hidden_size\n",
    "        \"\"\"\n",
    "\n",
    "        # ------------\n",
    "        # FILL THIS IN\n",
    "        # ------------\n",
    "        i = torch.sigmoid(self.Wii(x)+self.Whi(h_prev))\n",
    "        f = torch.sigmoid(self.Wif(x)+self.Whf(h_prev))\n",
    "        g = torch.tanh(self.Wig(x)+self.Whg(h_prev))\n",
    "        o = torch.sigmoid(self.Wio(x)+self.Who(h_prev))\n",
    "        c_new = torch.mul(f, c_prev) + torch.mul(i, g)\n",
    "        h_new = torch.mul(o, torch.tanh(c_new))\n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecEq4TP2lZ4Z"
   },
   "source": [
    "## Step 2: LSTM Encoder\n",
    "Please inspect the following recurrent encoder/decoder implementations. Make sure to run the cells before proceeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8jDNim2fmVJV"
   },
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, opts):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.opts = opts\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = MyLSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = inputs.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        cell = self.init_hidden(batch_size)\n",
    "\n",
    "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "        annotations = []\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
    "            hidden, cell = self.lstm(x, hidden, cell)\n",
    "            annotations.append(hidden)\n",
    "\n",
    "        annotations = torch.stack(annotations, dim=1)\n",
    "        return annotations, hidden, cell\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
    "        of a batch of sequences.\n",
    "\n",
    "        Arguments:\n",
    "            bs: The batch size for the initial hidden state.\n",
    "\n",
    "        Returns:\n",
    "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "        return to_var(torch.zeros(bs, self.hidden_size), self.opts.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HvwizYM9ma4p"
   },
   "outputs": [],
   "source": [
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = MyLSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
    "        \"\"\"Forward pass of the non-attentional decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch. (batch_size x seq_len)\n",
    "            annotations: This is not used here. It just maintains consistency with the\n",
    "                    interface used by the AttentionDecoder class.\n",
    "            hidden_init: The hidden states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
    "            cell_init: The cell states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
    "            None\n",
    "        \"\"\"        \n",
    "        batch_size, seq_len = inputs.size()\n",
    "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
    "\n",
    "        hiddens = []\n",
    "        h_prev = hidden_init\n",
    "        c_prev = cell_init\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            x = embed[:,i,:]  # Get the current time step input tokens, across the whole batch\n",
    "            h_prev, c_prev = self.rnn(x, h_prev, c_prev)  # batch_size x hidden_size\n",
    "            hiddens.append(h_prev)\n",
    "\n",
    "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
    "        \n",
    "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
    "        return output, None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSDTbsydlaGI"
   },
   "source": [
    "## Step 3: Training and Analysis\n",
    "Train the following language model comprised of recurrent encoder and decoders. \n",
    "\n",
    "First, we train on the smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmVuXTozTPF7",
    "outputId": "9dd21115-5214-4797-c574-df54f92616b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.005                                  \n",
      "                               lr_decay: 0.99                                   \n",
      "                early_stopping_patience: 20                                     \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: rnn                                    \n",
      "                           decoder_type: rnn                                    \n",
      "                         attention_type:                                        \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('impartiality', 'impartialityway')\n",
      "('bind', 'indbay')\n",
      "('follow', 'ollowfay')\n",
      "('piquet', 'iquetpay')\n",
      "('undressed', 'undressedway')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.421 | Val loss: 2.116 | Gen: ay-onay ay-onay insay-ontay-onay onay ontay-onay\n",
      "Epoch:   1 | Train loss: 1.917 | Val loss: 1.875 | Gen: ay-onday ay-ay illentay-onday ingway onstay-onday\n",
      "Epoch:   2 | Train loss: 1.721 | Val loss: 1.737 | Gen: etay artay illenstay-ay-onday ingway ongay-onday\n",
      "Epoch:   3 | Train loss: 1.580 | Val loss: 1.676 | Gen: etay artay onstay-outionday ingway ongtay-ay-ay\n",
      "Epoch:   4 | Train loss: 1.455 | Val loss: 1.620 | Gen: etay aray illlay-outeday-ay isay oongray-ay\n",
      "Epoch:   5 | Train loss: 1.352 | Val loss: 1.459 | Gen: etay artay ongingtionstay isway ongstay-ay\n",
      "Epoch:   6 | Train loss: 1.249 | Val loss: 1.482 | Gen: etay aray onstionstray-ay isway ongray-aty-ay\n",
      "Epoch:   7 | Train loss: 1.178 | Val loss: 1.416 | Gen: etay aray oncingstay-iteway isay orsionday\n",
      "Epoch:   8 | Train loss: 1.102 | Val loss: 1.350 | Gen: etay arway oncillway-outeway isay orsgay-iay\n",
      "Epoch:   9 | Train loss: 1.022 | Val loss: 1.319 | Gen: ethay arway ingetioncay-ouray isway orsgeray\n",
      "Epoch:  10 | Train loss: 0.986 | Val loss: 1.309 | Gen: etay arway oncillway-outay isay orsionay\n",
      "Epoch:  11 | Train loss: 0.937 | Val loss: 1.256 | Gen: ethay ariway oncionshay-ilehay isway orsionaway\n",
      "Epoch:  12 | Train loss: 0.878 | Val loss: 1.176 | Gen: ethay ariway oncionshetiopay isway orsionalay\n",
      "Epoch:  13 | Train loss: 0.826 | Val loss: 1.202 | Gen: ethay ariway onciitenetay isway orkionaway\n",
      "Epoch:  14 | Train loss: 0.787 | Val loss: 1.116 | Gen: ethay ay-aray onilionstay-omay isway orsionway\n",
      "Epoch:  15 | Train loss: 0.758 | Val loss: 1.106 | Gen: ehay ariway onincionetsay isway orkingway\n",
      "Epoch:  16 | Train loss: 0.715 | Val loss: 1.060 | Gen: ethay ariway oncilionedhay isway orkionsay\n",
      "Epoch:  17 | Train loss: 0.683 | Val loss: 1.026 | Gen: ethay ariway oningioncheray isway orkingway\n",
      "Epoch:  18 | Train loss: 0.652 | Val loss: 1.047 | Gen: ethay ariway oncioneshetcay isway orkingway\n",
      "Epoch:  19 | Train loss: 0.634 | Val loss: 1.139 | Gen: ehay ariway oncionshay-iehay isway orkingway\n",
      "Epoch:  20 | Train loss: 0.622 | Val loss: 0.976 | Gen: ethay ariway oningioncherhay isway orkingway\n",
      "Epoch:  21 | Train loss: 0.576 | Val loss: 0.955 | Gen: ehtay ariway oncioneshitway isway orkingway\n",
      "Epoch:  22 | Train loss: 0.556 | Val loss: 0.985 | Gen: ethay ariway oncilationsday isway orkingway\n",
      "Epoch:  23 | Train loss: 0.546 | Val loss: 0.978 | Gen: ethay ariway oncifionstay-omay isway orkingway\n",
      "Epoch:  24 | Train loss: 0.541 | Val loss: 1.011 | Gen: ethay ariway oncingitedtay isway oronsvay\n",
      "Epoch:  25 | Train loss: 0.509 | Val loss: 0.949 | Gen: ethay ariway oncionshetecay isway orkingway\n",
      "Epoch:  26 | Train loss: 0.485 | Val loss: 0.942 | Gen: ethay ariway oncionighetay isway orkingway\n",
      "Epoch:  27 | Train loss: 0.488 | Val loss: 0.996 | Gen: ehay ayidway oncingetionday isway orkingway\n",
      "Epoch:  28 | Train loss: 0.498 | Val loss: 0.978 | Gen: ethay ariway oncionightay isway orkieway\n",
      "Epoch:  29 | Train loss: 0.465 | Val loss: 0.918 | Gen: ethay ariway oncionionshay isway orkingway\n",
      "Epoch:  30 | Train loss: 0.433 | Val loss: 0.891 | Gen: ehtay ariway oncionighetay isway orkingway\n",
      "Epoch:  31 | Train loss: 0.415 | Val loss: 0.891 | Gen: ethay ariway oncionightay-ingay isway orkingway\n",
      "Epoch:  32 | Train loss: 0.395 | Val loss: 0.867 | Gen: ethay ariway oncionionshay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.382 | Val loss: 0.914 | Gen: ehtay ariway oncionighay-optay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.378 | Val loss: 0.864 | Gen: ethay ariway oncingitedtay isway orkingway\n",
      "Epoch:  35 | Train loss: 0.361 | Val loss: 0.856 | Gen: ehtay ariwway oncioniopestay isway orkingway\n",
      "Epoch:  36 | Train loss: 0.360 | Val loss: 0.936 | Gen: ehtay ariwway oncioniophenay isway orkionway\n",
      "Epoch:  37 | Train loss: 0.358 | Val loss: 0.924 | Gen: ehtay ariway oncionionshay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.351 | Val loss: 0.873 | Gen: ethay ariway oncionighay-itay isway orkingway\n",
      "Epoch:  39 | Train loss: 0.334 | Val loss: 0.882 | Gen: ethay ariwway oncionigherhay isway orkingway\n",
      "Epoch:  40 | Train loss: 0.329 | Val loss: 0.882 | Gen: ethay ariway oncionighetcay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.325 | Val loss: 0.974 | Gen: ethay ariwway oncionighay-opay isway orkionway\n",
      "Epoch:  42 | Train loss: 0.339 | Val loss: 0.948 | Gen: ethay ariwway oncionigherhay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.325 | Val loss: 0.888 | Gen: ethay ariway oncigingtoncay isway orkingway\n",
      "Epoch:  44 | Train loss: 0.301 | Val loss: 0.838 | Gen: ethay ariwway oncionighetcay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.286 | Val loss: 0.823 | Gen: ethay ariwway oncionighay-optay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.273 | Val loss: 0.857 | Gen: ethay ariwway oncionighetay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.267 | Val loss: 0.848 | Gen: ethay ariwway oncionighay-optay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.258 | Val loss: 0.868 | Gen: ethay ariwway oncionighetray isway orkingway\n",
      "Epoch:  49 | Train loss: 0.254 | Val loss: 0.874 | Gen: ethay ariwway oncigintway-etay isway orkingway\n",
      "Obtained lowest validation loss of: 0.8228752491108718\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay ariwway oncigintway-etay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "rnn_args_s = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True,\n",
    "              'nepochs':50,\n",
    "              'checkpoint_dir':\"checkpoints\",\n",
    "              'learning_rate':0.005,\n",
    "              'lr_decay':0.99,\n",
    "              'early_stopping_patience':20,\n",
    "              'batch_size':64,\n",
    "              'hidden_size':32,\n",
    "              'encoder_type': 'rnn', # options: rnn / transformer\n",
    "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
    "              'attention_type': '',  # options: additive / scaled_dot\n",
    "}\n",
    "rnn_args_s.update(args_dict)\n",
    "\n",
    "print_opts(rnn_args_s)\n",
    "rnn_encode_s, rnn_decoder_s, rnn_losses_s = train(rnn_args_s)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_encode_s, rnn_decoder_s, None, rnn_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mR97V_NtER6"
   },
   "source": [
    "Next, we train on the larger dataset. This experiment investigates if increasing dataset size improves model generalization on the validation set. \n",
    "\n",
    "For a fair comparison, the number of iterations (not number of epochs) for each run should be similar. This is done in a rough and dirty way by adjusting the batch size so approximately the same number of batches is processed per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3YLrAjsmx_W",
    "outputId": "35fd6f44-5801-4140-abe5-faeffe96afa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_large                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.005                                  \n",
      "                               lr_decay: 0.99                                   \n",
      "                early_stopping_patience: 10                                     \n",
      "                             batch_size: 512                                    \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: rnn                                    \n",
      "                           decoder_type: rnn                                    \n",
      "                         attention_type:                                        \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('blood', 'oodblay')\n",
      "('wen', 'enway')\n",
      "('anthem', 'anthemway')\n",
      "('starch', 'archstay')\n",
      "('homepage', 'omepagehay')\n",
      "Num unique word pairs: 22402\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.372 | Val loss: 2.098 | Gen: eray-ay ay-ay-ay onstay-onsay-ay-ay-a onsay onsay-ay-ay-ay-ay\n",
      "Epoch:   1 | Train loss: 1.882 | Val loss: 1.889 | Gen: ay-ay ay-ay ontay-onsay-onsay ingay ontay-onsay\n",
      "Epoch:   2 | Train loss: 1.695 | Val loss: 1.928 | Gen: entay atay-ay ongay-ingeray-inway- onway ontay-ingay-ay\n",
      "Epoch:   3 | Train loss: 1.573 | Val loss: 1.642 | Gen: enway ay-awlay ongay-ingay-ingay-ay ingay ongay-ingay\n",
      "Epoch:   4 | Train loss: 1.432 | Val loss: 1.672 | Gen: entay away ongay-illay-inway inway ongay-ingway\n",
      "Epoch:   5 | Train loss: 1.356 | Val loss: 1.590 | Gen: etay away ongay-ingay-inway inway ongay-inway\n",
      "Epoch:   6 | Train loss: 1.264 | Val loss: 1.498 | Gen: etay away ongay-inglay-inway isway onglay-ybay\n",
      "Epoch:   7 | Train loss: 1.182 | Val loss: 1.390 | Gen: ethay away ongay-inglay-ingway isway odgay-orday\n",
      "Epoch:   8 | Train loss: 1.106 | Val loss: 1.359 | Gen: eheway arway ongay-inglay-inway isway onglay-edway\n",
      "Epoch:   9 | Train loss: 1.059 | Val loss: 1.364 | Gen: ehay arway onglay-inglay-away isway ondedtay\n",
      "Epoch:  10 | Train loss: 1.000 | Val loss: 1.275 | Gen: ehay arway onglay-ingcingway isway ordinayway\n",
      "Epoch:  11 | Train loss: 0.933 | Val loss: 1.168 | Gen: eheway airway ongicintinlay isway oodingway\n",
      "Epoch:  12 | Train loss: 0.870 | Val loss: 1.166 | Gen: ehay ariway odingconinay-awlay isway onditinway\n",
      "Epoch:  13 | Train loss: 0.823 | Val loss: 1.133 | Gen: ehay airway odingconincay isway oringlay\n",
      "Epoch:  14 | Train loss: 0.791 | Val loss: 1.140 | Gen: ehay airway ondingcinticay isway oringlay\n",
      "Epoch:  15 | Train loss: 0.771 | Val loss: 1.130 | Gen: ehay airway ondingcintinay isway oudintway\n",
      "Epoch:  16 | Train loss: 0.740 | Val loss: 1.024 | Gen: eheway ariway ondinicintay-owlay isway ornickway\n",
      "Epoch:  17 | Train loss: 0.704 | Val loss: 1.071 | Gen: eheway ariway ondingliconmay isway oruginay\n",
      "Epoch:  18 | Train loss: 0.684 | Val loss: 1.004 | Gen: eheway ariway ondinicintinay isway orkingway\n",
      "Epoch:  19 | Train loss: 0.664 | Val loss: 1.133 | Gen: etway airway ondinicintay-awlay isway onidmpaykay\n",
      "Epoch:  20 | Train loss: 0.699 | Val loss: 1.046 | Gen: eheway airway ondinticongiway isway oniordmay\n",
      "Epoch:  21 | Train loss: 0.657 | Val loss: 0.984 | Gen: eheway ariway ondinicimationway isway orkingway\n",
      "Epoch:  22 | Train loss: 0.614 | Val loss: 0.969 | Gen: ethay airway ondinicintay-iway isway oniorglway\n",
      "Epoch:  23 | Train loss: 0.580 | Val loss: 0.907 | Gen: eheway airway onditinginaycay isway orkingway\n",
      "Epoch:  24 | Train loss: 0.558 | Val loss: 0.901 | Gen: eheway airway ondinicationglay isway orkingway\n",
      "Epoch:  25 | Train loss: 0.553 | Val loss: 0.941 | Gen: ethay airway onditiningcay isway oniordkay\n",
      "Epoch:  26 | Train loss: 0.541 | Val loss: 0.894 | Gen: ethay ariway oringlingcay-awlay isway oniorglway\n",
      "Epoch:  27 | Train loss: 0.523 | Val loss: 0.896 | Gen: ehetay ariway onidingsay-oitalway isway orkingway\n",
      "Epoch:  28 | Train loss: 0.516 | Val loss: 0.995 | Gen: ehetay ary indonicimatinay isway oniordway\n",
      "Epoch:  29 | Train loss: 0.521 | Val loss: 0.876 | Gen: ethay ariway oringlinationdway isway orkingway\n",
      "Epoch:  30 | Train loss: 0.494 | Val loss: 0.865 | Gen: ehetay ariway ondiconitingway isway orkingway\n",
      "Epoch:  31 | Train loss: 0.496 | Val loss: 0.892 | Gen: ethay ariway onditingcay-inway isway onirkway\n",
      "Epoch:  32 | Train loss: 0.495 | Val loss: 0.875 | Gen: ethay ariway onidinticatinay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.468 | Val loss: 0.862 | Gen: ehtway ariway onditingcay-ineway isway orkingway\n",
      "Epoch:  34 | Train loss: 0.457 | Val loss: 0.855 | Gen: ethay ariway orintingcalinway isway orkingway\n",
      "Epoch:  35 | Train loss: 0.436 | Val loss: 0.825 | Gen: ethay ariway ondinicationglay isway orkingway\n",
      "Epoch:  36 | Train loss: 0.421 | Val loss: 0.812 | Gen: ethay ariway onditingcay-inway isway orkingway\n",
      "Epoch:  37 | Train loss: 0.410 | Val loss: 0.796 | Gen: ethay ariway ontidingcay-onedway isway orkingway\n",
      "Epoch:  38 | Train loss: 0.400 | Val loss: 0.820 | Gen: ethay ariway ondinticationdway isway orkingway\n",
      "Epoch:  39 | Train loss: 0.405 | Val loss: 0.848 | Gen: eethay ariway orniscinatingway isway orkingway\n",
      "Epoch:  40 | Train loss: 0.439 | Val loss: 0.913 | Gen: ethay ariway ontindicatingway isway orkingway\n",
      "Epoch:  41 | Train loss: 0.453 | Val loss: 1.001 | Gen: ethay airway ondinticatingway isway orkingway\n",
      "Epoch:  42 | Train loss: 0.434 | Val loss: 0.810 | Gen: ethway ariway ontidingcay-ionlay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.389 | Val loss: 0.750 | Gen: ethay ariway onditingcay-alway isway orkingway\n",
      "Epoch:  44 | Train loss: 0.361 | Val loss: 0.731 | Gen: ethay ariway ontidingcalway isway orkingway\n",
      "Epoch:  45 | Train loss: 0.348 | Val loss: 0.731 | Gen: ethay ariway ontidingcay-alwceay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.340 | Val loss: 0.744 | Gen: ethay airway ontidingcay-alewcay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.338 | Val loss: 0.755 | Gen: ethay airway ontidingcalimay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.335 | Val loss: 0.704 | Gen: ethay ariway ontidingcay-aceyway isway orkingway\n",
      "Epoch:  49 | Train loss: 0.332 | Val loss: 0.816 | Gen: ethay airway onditingcay-aceyway isway orkingway\n",
      "Obtained lowest validation loss of: 0.7035043166122503\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditingcay-aceyway isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "rnn_args_l = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_large',\n",
    "              'cuda':True,\n",
    "              'nepochs':50,\n",
    "              'checkpoint_dir':\"checkpoints\",\n",
    "              'learning_rate':0.005,\n",
    "              'lr_decay':0.99,\n",
    "              'early_stopping_patience':10,\n",
    "              'batch_size':512,\n",
    "              'hidden_size':32,\n",
    "              'encoder_type': 'rnn', # options: rnn / transformer\n",
    "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
    "              'attention_type': '',  # options: additive / scaled_dot\n",
    "}\n",
    "rnn_args_l.update(args_dict)\n",
    "\n",
    "print_opts(rnn_args_l)\n",
    "rnn_encode_l, rnn_decoder_l, rnn_losses_l = train(rnn_args_l)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_encode_l, rnn_decoder_l, None, rnn_args_l)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01HsZ6EItc56"
   },
   "source": [
    "The code below plots the training and validation losses of each model, as a function of the number of gradient descent iterations. Consider if there are significant differences in the validation performance of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Qyk_9-Fwtekj",
    "outputId": "91d29f98-89ce-49ba-d267-7c82d18e4604"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_loss_comparison_lstm(rnn_losses_s, rnn_losses_l, rnn_args_s, rnn_args_l, 'lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cE4ijaCzneAt"
   },
   "source": [
    "Select best performing model, and try translating different sentences by changing the variable TEST_SENTENCE. Identify a failure mode and briefly describe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrNnz8W1nULf",
    "outputId": "c0d417bc-dc4c-41a1-ccb2-82e49a6c155e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\t\tthis is phenomenal \n",
      "translated:\tisthay isway enovablinay\n"
     ]
    }
   ],
   "source": [
    "best_encoder = rnn_encode_l # Replace with rnn_losses_s or rnn_losses l\n",
    "best_decoder = rnn_decoder_l # etc.\n",
    "best_args = rnn_args_l\n",
    "\n",
    "TEST_SENTENCE = 'this is phenomenal'\n",
    "translated = translate_sentence(TEST_SENTENCE, best_encoder, best_decoder, None, best_args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWwA6OGqlaTq"
   },
   "source": [
    "# Part 2: Additive Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJSafHSAmu_w"
   },
   "source": [
    "## Step 1: Additive Attention\n",
    "Already implemented the additive attention mechanism. Write down the mathematical expression for $\\tilde{\\alpha}_i^{(t)}, \\alpha_i^{(t)}, c_t$ as a function of $W_1, W_2, b_1, b_2, Q_t, K_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AdewEVSMo5jJ"
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # A two layer fully-connected network\n",
    "        # hidden_size*2 --> hidden_size, ReLU, hidden_size --> 1\n",
    "        self.attention_network = nn.Sequential(\n",
    "                                    nn.Linear(hidden_size*2, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(hidden_size, 1)\n",
    "                                 )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"The forward pass of the additive attention mechanism.\n",
    "\n",
    "        Arguments:\n",
    "            queries: The current decoder hidden state. (batch_size x hidden_size)\n",
    "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            context: weighted average of the values (batch_size x 1 x hidden_size)\n",
    "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
    "\n",
    "            The attention_weights must be a softmax weighting over the seq_len annotations.\n",
    "        \"\"\"\n",
    "        batch_size = keys.size(0)\n",
    "        expanded_queries = queries.view(batch_size, -1, self.hidden_size).expand_as(keys)\n",
    "        concat_inputs = torch.cat([expanded_queries, keys], dim=2)\n",
    "        unnormalized_attention = self.attention_network(concat_inputs)\n",
    "        attention_weights = self.softmax(unnormalized_attention)\n",
    "        context = torch.bmm(attention_weights.transpose(2,1), values)\n",
    "        return context, attention_weights\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73_p8d5EmvOJ"
   },
   "source": [
    "## Step 2: RNN Additive Attention Decoder\n",
    "We will now implement a recurrent decoder that makes use of the additive attention mechanism. Read the description in the assignment worksheet and complete the following implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RJaABkXrpJSw"
   },
   "outputs": [],
   "source": [
    "class RNNAttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, attention_type='scaled_dot'):\n",
    "        super(RNNAttentionDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        self.rnn = MyLSTMCell(input_size=hidden_size*2, hidden_size=hidden_size)\n",
    "        if attention_type == 'additive':\n",
    "          self.attention = AdditiveAttention(hidden_size=hidden_size)\n",
    "        elif attention_type == 'scaled_dot':\n",
    "          self.attention = ScaledDotAttention(hidden_size=hidden_size)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
    "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
    "            annotations: The encoder hidden states for each step of the input.\n",
    "                         sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden_init: The final hidden states from the encoder, across a batch. (batch_size x hidden_size)\n",
    "            cell_init: The final cell states from the encoder, across a batch. (batch_size x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
    "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, seq_len = inputs.size()\n",
    "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
    "\n",
    "        hiddens = []\n",
    "        attentions = []\n",
    "        h_prev = hidden_init\n",
    "        c_prev = cell_init\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            embed_current = embed[:,i,:]  # Get the current time step, across the whole batch\n",
    "            context, attention_weights = self.attention(h_prev, annotations, annotations)  # batch_size x 1 x hidden_size\n",
    "            embed_and_context = torch.cat([embed_current, context.squeeze(1)], dim=1)  # batch_size x (2*hidden_size)\n",
    "            h_prev, c_prev = self.rnn(embed_and_context, h_prev, c_prev)  # batch_size x hidden_size            \n",
    "            \n",
    "            \n",
    "            hiddens.append(h_prev)\n",
    "            attentions.append(attention_weights)\n",
    "\n",
    "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
    "        attentions = torch.cat(attentions, dim=2) # batch_size x seq_len x seq_len\n",
    "        \n",
    "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
    "        return output, attentions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYPae08Io1Fi"
   },
   "source": [
    "## Step 3: Training and Analysis\n",
    "Train the following language model that uses a recurrent encoder, and a recurrent decoder that has an additive attention component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ke6t6rCezpZV",
    "outputId": "6eec8bdf-6783-4c6a-dd4a-1d85e370039c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.005                                  \n",
      "                               lr_decay: 0.99                                   \n",
      "                early_stopping_patience: 10                                     \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 64                                     \n",
      "                           encoder_type: rnn                                    \n",
      "                           decoder_type: rnn_attention                          \n",
      "                         attention_type: additive                               \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('impartiality', 'impartialityway')\n",
      "('bind', 'indbay')\n",
      "('follow', 'ollowfay')\n",
      "('piquet', 'iquetpay')\n",
      "('undressed', 'undressedway')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.130 | Val loss: 1.936 | Gen: eay-ontay ay-ay ontay-onday-onday illlllly ontay-onday\n",
      "Epoch:   1 | Train loss: 1.635 | Val loss: 1.732 | Gen: estay-ay artay intingtay-onday issay ortay-onday\n",
      "Epoch:   2 | Train loss: 1.369 | Val loss: 1.609 | Gen: ecay arway onstingstingstay issay orngstingway\n",
      "Epoch:   3 | Train loss: 1.137 | Val loss: 1.386 | Gen: etay arway ontingstay-inday isway oncray-ingsay\n",
      "Epoch:   4 | Train loss: 0.933 | Val loss: 1.276 | Gen: ecay arway oncingsay-ondway isway ordingway\n",
      "Epoch:   5 | Train loss: 0.778 | Val loss: 1.134 | Gen: ethay arinay ontincinistay issay oncingway\n",
      "Epoch:   6 | Train loss: 0.661 | Val loss: 1.187 | Gen: ehay arioway ontingcay-inday isway ongrway\n",
      "Epoch:   7 | Train loss: 0.541 | Val loss: 0.834 | Gen: ethay airway ondiondioncay isway orkingway\n",
      "Epoch:   8 | Train loss: 0.407 | Val loss: 0.858 | Gen: ethay ariway ondionmingtay isway orkingway\n",
      "Epoch:   9 | Train loss: 0.339 | Val loss: 0.825 | Gen: ethay airway onditingtay-igay isway orkingway\n",
      "Epoch:  10 | Train loss: 0.287 | Val loss: 0.723 | Gen: ethay ariway ondionitingcay isway orkingway\n",
      "Epoch:  11 | Train loss: 0.205 | Val loss: 0.578 | Gen: ethay airway onditinginay isway orkingway\n",
      "Epoch:  12 | Train loss: 0.153 | Val loss: 0.634 | Gen: ethay airway onditingincay isway orkingway\n",
      "Epoch:  13 | Train loss: 0.133 | Val loss: 0.659 | Gen: ethay airway onditingitycay isway orkingway\n",
      "Epoch:  14 | Train loss: 0.134 | Val loss: 0.680 | Gen: ethay ariway ondionitingcay isway orkingway\n",
      "Epoch:  15 | Train loss: 0.146 | Val loss: 0.587 | Gen: ethay airway ondionitincay isway orkway-ingway\n",
      "Epoch:  16 | Train loss: 0.122 | Val loss: 0.544 | Gen: ethay airway ondiningingcay isway orkingway\n",
      "Epoch:  17 | Train loss: 0.074 | Val loss: 0.450 | Gen: ethay airway onditinioncay isway orkingway\n",
      "Epoch:  18 | Train loss: 0.047 | Val loss: 0.439 | Gen: ethay airway ondioningincay isway orkingway\n",
      "Epoch:  19 | Train loss: 0.033 | Val loss: 0.397 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  20 | Train loss: 0.029 | Val loss: 0.387 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  21 | Train loss: 0.025 | Val loss: 0.379 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  22 | Train loss: 0.021 | Val loss: 0.363 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  23 | Train loss: 0.018 | Val loss: 0.468 | Gen: ethay airway onditingingcay isway orkingway\n",
      "Epoch:  24 | Train loss: 0.018 | Val loss: 0.428 | Gen: ethay airway onditiningcay isway orkingway\n",
      "Epoch:  25 | Train loss: 0.012 | Val loss: 0.368 | Gen: ethay airway onditiningcay isway orkingway\n",
      "Epoch:  26 | Train loss: 0.009 | Val loss: 0.345 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  27 | Train loss: 0.007 | Val loss: 0.335 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  28 | Train loss: 0.006 | Val loss: 0.335 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  29 | Train loss: 0.005 | Val loss: 0.333 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  30 | Train loss: 0.004 | Val loss: 0.331 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  31 | Train loss: 0.004 | Val loss: 0.330 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  32 | Train loss: 0.003 | Val loss: 0.331 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.003 | Val loss: 0.330 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.003 | Val loss: 0.331 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  35 | Train loss: 0.003 | Val loss: 0.332 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  36 | Train loss: 0.002 | Val loss: 0.332 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  37 | Train loss: 0.002 | Val loss: 0.332 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.002 | Val loss: 0.332 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  39 | Train loss: 0.002 | Val loss: 0.332 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  40 | Train loss: 0.002 | Val loss: 0.333 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.002 | Val loss: 0.333 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Validation loss has not improved in 10 epochs, stopping early\n",
      "Obtained lowest validation loss of: 0.329927248519934\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditioningcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "rnn_attn_args = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True, \n",
    "              'nepochs':50, \n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':0.005,\n",
    "              'lr_decay':0.99,\n",
    "              'early_stopping_patience':10,\n",
    "              'batch_size':64, \n",
    "              'hidden_size':64, \n",
    "              'encoder_type': 'rnn', # options: rnn / transformer\n",
    "              'decoder_type': 'rnn_attention', # options: rnn / rnn_attention / transformer\n",
    "              'attention_type': 'additive',  # options: additive / scaled_dot\n",
    "}\n",
    "rnn_attn_args.update(args_dict)\n",
    "\n",
    "print_opts(rnn_attn_args)\n",
    "rnn_attn_encoder, rnn_attn_decoder, rnn_attn_losses = train(rnn_attn_args)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, rnn_attn_args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNVKbLc0ACj_",
    "outputId": "a37f139e-948d-4828-df65-e08bb18a6f34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditioningcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, rnn_attn_args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw_GOIvzo1ix"
   },
   "source": [
    "# Part 3: Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq7nhsEio1w-"
   },
   "source": [
    "## Step 1: Implement Dot-Product Attention\n",
    "Implement the scaled dot product attention module described in the assignment worksheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "d_j3oY3hqsJQ"
   },
   "outputs": [],
   "source": [
    "class ScaledDotAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(ScaledDotAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
    "        self.K = nn.Linear(hidden_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
    "\n",
    "        Arguments:\n",
    "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
    "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            context: weighted average of the values (batch_size x k x hidden_size)\n",
    "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
    "\n",
    "            The output must be a softmax weighting over the seq_len annotations.\n",
    "        \"\"\"\n",
    "\n",
    "        # ------------\n",
    "        # FILL THIS IN\n",
    "        # ------------\n",
    "        batch_size = keys.size(0)\n",
    "        q = self.Q(queries).view(batch_size, -1, self.hidden_size)\n",
    "        k = self.K(keys).view(batch_size, -1, self.hidden_size)\n",
    "        v = self.V(values).view(batch_size, -1, self.hidden_size)\n",
    "        unnormalized_attention = torch.bmm(k, q.transpose(2,1)) * self.scaling_factor\n",
    "        attention_weights = self.softmax(unnormalized_attention)\n",
    "        context = torch.bmm(attention_weights.transpose(2,1), v)\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unReAOrjo113"
   },
   "source": [
    "## Step 2: Implement Causal Dot-Product Attention\n",
    "Now implement the scaled causal dot product described in the assignment worksheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ovigzQffrKqj"
   },
   "outputs": [],
   "source": [
    "class CausalScaledDotAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(CausalScaledDotAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.neg_inf = torch.tensor(-1e7)\n",
    "\n",
    "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
    "        self.K = nn.Linear(hidden_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
    "\n",
    "        Arguments:\n",
    "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
    "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            context: weighted average of the values (batch_size x k x hidden_size)\n",
    "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
    "\n",
    "            The output must be a softmax weighting over the seq_len annotations.\n",
    "        \"\"\"\n",
    "\n",
    "        # ------------\n",
    "        # FILL THIS IN\n",
    "        # ------------\n",
    "        batch_size = keys.size(0)\n",
    "        q = self.Q(queries).view(batch_size, -1, self.hidden_size)\n",
    "        k = self.K(keys).view(batch_size, -1, self.hidden_size)\n",
    "        v = self.V(values).view(batch_size, -1, self.hidden_size)\n",
    "        unnormalized_attention = torch.bmm(k, q.transpose(2,1)) * self.scaling_factor\n",
    "        mask = torch.tril(self.neg_inf * torch.ones(unnormalized_attention.size()), diagonal=-1).cuda()\n",
    "        attention_weights = self.softmax(unnormalized_attention + mask)\n",
    "        context = torch.bmm(attention_weights.transpose(2,1), v)\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tcpUFKqo2Oi"
   },
   "source": [
    "## Step 3: Transformer Encoder\n",
    "Complete the following transformer encoder implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "N3B-fWsarlVk"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers, opts):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.opts = opts\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        \n",
    "        self.self_attentions = nn.ModuleList([ScaledDotAttention(\n",
    "                                    hidden_size=hidden_size, \n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.attention_mlps = nn.ModuleList([nn.Sequential(\n",
    "                                    nn.Linear(hidden_size, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                 ) for i in range(self.num_layers)])\n",
    "\n",
    "        self.positional_encodings = self.create_positional_encodings()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            None: Used to conform to standard encoder return signature.\n",
    "            None: Used to conform to standard encoder return signature.        \n",
    "        \"\"\"\n",
    "        batch_size, seq_len = inputs.size()\n",
    "\n",
    "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "\n",
    "        # Add positinal embeddings from self.create_positional_encodings. (a'la https://arxiv.org/pdf/1706.03762.pdf, section 3.5)\n",
    "        encoded = encoded + self.positional_encodings[:seq_len]\n",
    "\n",
    "        annotations = encoded\n",
    "        for i in range(self.num_layers):\n",
    "            new_annotations, self_attention_weights = self.self_attentions[i](annotations, annotations, annotations)  # batch_size x seq_len x hidden_size\n",
    "            residual_annotations = annotations + new_annotations\n",
    "            new_annotations = self.attention_mlps[i](residual_annotations)\n",
    "            annotations = residual_annotations + new_annotations\n",
    "\n",
    "        # Transformer encoder does not have a last hidden or cell layer. \n",
    "        return annotations, None, None\n",
    "\n",
    "    def create_positional_encodings(self, max_seq_len=1000):\n",
    "        \"\"\"Creates positional encodings for the inputs.\n",
    "\n",
    "        Arguments:\n",
    "            max_seq_len: a number larger than the maximum string length we expect to encounter during training\n",
    "\n",
    "        Returns:\n",
    "            pos_encodings: (max_seq_len, hidden_dim) Positional encodings for a sequence with length max_seq_len. \n",
    "        \"\"\"\n",
    "        pos_indices = torch.arange(max_seq_len)[..., None]\n",
    "        dim_indices = torch.arange(self.hidden_size//2)[None, ...]\n",
    "        exponents = (2*dim_indices).float()/(self.hidden_size)\n",
    "        trig_args = pos_indices / (10000**exponents)\n",
    "        sin_terms = torch.sin(trig_args)\n",
    "        cos_terms = torch.cos(trig_args)\n",
    "\n",
    "        pos_encodings = torch.zeros((max_seq_len, self.hidden_size))\n",
    "        pos_encodings[:, 0::2] = sin_terms\n",
    "        pos_encodings[:, 1::2] = cos_terms\n",
    "\n",
    "        if self.opts.cuda:\n",
    "            pos_encodings = pos_encodings.cuda()\n",
    "\n",
    "        return pos_encodings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1hDi020rT36"
   },
   "source": [
    "## Step 4: Transformer Decoder\n",
    "Complete the following transformer decoder implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "nyvTZFxtrvc6"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.self_attentions = nn.ModuleList([CausalScaledDotAttention(\n",
    "                                    hidden_size=hidden_size, \n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.encoder_attentions = nn.ModuleList([ScaledDotAttention(\n",
    "                                    hidden_size=hidden_size, \n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.attention_mlps = nn.ModuleList([nn.Sequential(\n",
    "                                    nn.Linear(hidden_size, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        self.positional_encodings = self.create_positional_encodings()\n",
    "\n",
    "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
    "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
    "            annotations: The encoder hidden states for each step of the input.\n",
    "                         sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden_init: Not used in the transformer decoder\n",
    "            cell_init: Not used in transformer decoder\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
    "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, seq_len = inputs.size()\n",
    "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "\n",
    "        embed = embed + self.positional_encodings[:seq_len]\n",
    "\n",
    "        encoder_attention_weights_list = []\n",
    "        self_attention_weights_list = []\n",
    "        contexts = embed\n",
    "        for i in range(self.num_layers):\n",
    "            new_contexts, self_attention_weights = self.self_attentions[i](contexts, contexts, contexts)  # batch_size x seq_len x hidden_size\n",
    "            residual_contexts = contexts + new_contexts\n",
    "            new_contexts, encoder_attention_weights = self.encoder_attentions[i](residual_contexts, annotations, annotations) # batch_size x seq_len x hidden_size\n",
    "            residual_contexts = residual_contexts + new_contexts\n",
    "            new_contexts = self.attention_mlps[i](residual_contexts)\n",
    "            contexts = residual_contexts + new_contexts\n",
    "\n",
    "            encoder_attention_weights_list.append(encoder_attention_weights)\n",
    "            self_attention_weights_list.append(self_attention_weights)\n",
    "          \n",
    "        output = self.out(contexts)\n",
    "        encoder_attention_weights = torch.stack(encoder_attention_weights_list)\n",
    "        self_attention_weights = torch.stack(self_attention_weights_list)\n",
    "        \n",
    "        return output, (encoder_attention_weights, self_attention_weights)\n",
    "\n",
    "    def create_positional_encodings(self, max_seq_len=1000):\n",
    "        \"\"\"Creates positional encodings for the inputs.\n",
    "\n",
    "        Arguments:\n",
    "            max_seq_len: a number larger than the maximum string length we expect to encounter during training\n",
    "\n",
    "        Returns:\n",
    "            pos_encodings: (max_seq_len, hidden_dim) Positional encodings for a sequence with length max_seq_len. \n",
    "        \"\"\"\n",
    "        pos_indices = torch.arange(max_seq_len)[..., None]\n",
    "        dim_indices = torch.arange(self.hidden_size//2)[None, ...]\n",
    "        exponents = (2*dim_indices).float()/(self.hidden_size)\n",
    "        trig_args = pos_indices / (10000**exponents)\n",
    "        sin_terms = torch.sin(trig_args)\n",
    "        cos_terms = torch.cos(trig_args)\n",
    "\n",
    "        pos_encodings = torch.zeros((max_seq_len, self.hidden_size))\n",
    "        pos_encodings[:, 0::2] = sin_terms\n",
    "        pos_encodings[:, 1::2] = cos_terms\n",
    "\n",
    "        pos_encodings = pos_encodings.cuda()\n",
    "\n",
    "        return pos_encodings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29ZjkXTNrUKb"
   },
   "source": [
    "\n",
    "## Step 5: Training and analysis\n",
    "Now, train the following language model that's comprised of a (simplified) transformer encoder and transformer decoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqTp-eCPuuFO"
   },
   "source": [
    "First, we train our smaller model on the small dataset. Use this model to answer Question 4 in the handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk8e4KSnuZ8N",
    "outputId": "d1cbf49b-8354-4095-cbdb-146c29a30745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 100                                    \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 100                                    \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('impartiality', 'impartialityway')\n",
      "('bind', 'indbay')\n",
      "('follow', 'ollowfay')\n",
      "('piquet', 'iquetpay')\n",
      "('undressed', 'undressedway')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.892 | Val loss: 2.461 | Gen: ay ay ininay ay ionay\n",
      "Epoch:   1 | Train loss: 2.166 | Val loss: 2.073 | Gen: ay ay inonay----day ay inonay\n",
      "Epoch:   2 | Train loss: 1.896 | Val loss: 1.855 | Gen: ay anay inonay isay inonay\n",
      "Epoch:   3 | Train loss: 1.715 | Val loss: 1.754 | Gen: ay anay inongway isay ongway\n",
      "Epoch:   4 | Train loss: 1.583 | Val loss: 1.672 | Gen: atthay atay ononongionay isay ougway\n",
      "Epoch:   5 | Train loss: 1.480 | Val loss: 1.677 | Gen: atthay iray ongway-onionontionon isway ongway\n",
      "Epoch:   6 | Train loss: 1.401 | Val loss: 1.585 | Gen: ettay ariray ongiongiongiongway isway ongway\n",
      "Epoch:   7 | Train loss: 1.317 | Val loss: 1.597 | Gen: aththay iray onongiongiongway isway ougway\n",
      "Epoch:   8 | Train loss: 1.244 | Val loss: 1.523 | Gen: etttay iray oingngiongiongway isway ongingay\n",
      "Epoch:   9 | Train loss: 1.180 | Val loss: 1.496 | Gen: ettay arirway ongingiongiongway isway ongway\n",
      "Epoch:  10 | Train loss: 1.129 | Val loss: 1.474 | Gen: ethay arirway onongingiongway isway ongway\n",
      "Epoch:  11 | Train loss: 1.096 | Val loss: 1.424 | Gen: ethay ariray ongingiongionay isway ongway\n",
      "Epoch:  12 | Train loss: 1.040 | Val loss: 1.508 | Gen: ethay awirway onondingiongway isway ookingway\n",
      "Epoch:  13 | Train loss: 1.017 | Val loss: 1.445 | Gen: eththay ariway ondingway isway okwingway\n",
      "Epoch:  14 | Train loss: 0.999 | Val loss: 1.474 | Gen: ehay ariway ondiongingway isway ookugway\n",
      "Epoch:  15 | Train loss: 0.931 | Val loss: 1.398 | Gen: ehhay ariway ondingiongway isway okugway\n",
      "Epoch:  16 | Train loss: 0.887 | Val loss: 1.337 | Gen: ehthay ariway ondingiongway isway okingway\n",
      "Epoch:  17 | Train loss: 0.848 | Val loss: 1.333 | Gen: ehthay ariway ondionginginay isway ookingway\n",
      "Epoch:  18 | Train loss: 0.812 | Val loss: 1.303 | Gen: ehthay ariway ondingiongway isway okingway\n",
      "Epoch:  19 | Train loss: 0.783 | Val loss: 1.237 | Gen: ehay ariway ondingionginay isway okingway\n",
      "Epoch:  20 | Train loss: 0.743 | Val loss: 1.263 | Gen: ehthay ariway ondingiongingway isway okongway\n",
      "Epoch:  21 | Train loss: 0.727 | Val loss: 1.215 | Gen: ethay ariway ondingcay isway okwingway\n",
      "Epoch:  22 | Train loss: 0.722 | Val loss: 1.199 | Gen: ehay ariway ondingingcay isway okongway\n",
      "Epoch:  23 | Train loss: 0.665 | Val loss: 1.177 | Gen: ehay ariway ondingiongway isway okingway\n",
      "Epoch:  24 | Train loss: 0.636 | Val loss: 1.137 | Gen: ehthay ariway ondingiongcay isway okingway\n",
      "Epoch:  25 | Train loss: 0.609 | Val loss: 1.180 | Gen: ehay ariway ondiongway isway okwingway\n",
      "Epoch:  26 | Train loss: 0.606 | Val loss: 1.116 | Gen: ehay ariway ondingiongingway isway okingway\n",
      "Epoch:  27 | Train loss: 0.583 | Val loss: 1.160 | Gen: ethay ariway onditioncay isway okwingway\n",
      "Epoch:  28 | Train loss: 0.564 | Val loss: 1.140 | Gen: ehthay ariway ondingcay isway orkingway\n",
      "Epoch:  29 | Train loss: 0.542 | Val loss: 1.175 | Gen: ehaththay ariway onditioncay isway okwighway\n",
      "Epoch:  30 | Train loss: 0.541 | Val loss: 1.083 | Gen: ehay ariway ondicandiongcay isway okwingway\n",
      "Epoch:  31 | Train loss: 0.528 | Val loss: 1.166 | Gen: ehthay ariway ondicatiniongcay isway okwingway\n",
      "Epoch:  32 | Train loss: 0.517 | Val loss: 1.173 | Gen: ehathhway ariway ondititioncindionday isway okwingway\n",
      "Epoch:  33 | Train loss: 0.510 | Val loss: 1.079 | Gen: ehaththay ariway ondicationdinay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.473 | Val loss: 1.015 | Gen: ehathhhay ariway onditingcay isway okingway\n",
      "Epoch:  35 | Train loss: 0.443 | Val loss: 1.022 | Gen: ehay ariway onditingcay isway okwingway\n",
      "Epoch:  36 | Train loss: 0.431 | Val loss: 1.020 | Gen: ehathhhway ariway onditincay isway okwingway\n",
      "Epoch:  37 | Train loss: 0.432 | Val loss: 1.022 | Gen: ehay ariway onditingway isway orkingway\n",
      "Epoch:  38 | Train loss: 0.415 | Val loss: 0.980 | Gen: ehay-athay ariway onditincay isway okwingway\n",
      "Epoch:  39 | Train loss: 0.390 | Val loss: 0.980 | Gen: ehay ariway ondititingcay isway okwingway\n",
      "Epoch:  40 | Train loss: 0.372 | Val loss: 0.982 | Gen: ehathhway ariway ondititincay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.362 | Val loss: 0.961 | Gen: ehay ariway onditingingway isway orkingway\n",
      "Epoch:  42 | Train loss: 0.348 | Val loss: 0.988 | Gen: ehathway ariway ondititincay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.340 | Val loss: 0.968 | Gen: ehay ariway onditingway isway orkingway\n",
      "Epoch:  44 | Train loss: 0.326 | Val loss: 0.977 | Gen: ehathway ariway ondititingcay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.315 | Val loss: 0.955 | Gen: ehay ariway onditinginay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.305 | Val loss: 0.982 | Gen: ehathway ariway ondititingcay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.301 | Val loss: 0.953 | Gen: ehathway ariway onditinginay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.285 | Val loss: 0.960 | Gen: ehay ariway ondititingcay isway orkingway\n",
      "Epoch:  49 | Train loss: 0.276 | Val loss: 0.951 | Gen: ehay ariway onditinginay isway orkingway\n",
      "Epoch:  50 | Train loss: 0.267 | Val loss: 0.945 | Gen: ehay ariway ondititingcay isway orkingway\n",
      "Epoch:  51 | Train loss: 0.270 | Val loss: 0.951 | Gen: ehay ariway ondititioncay isway orkingway\n",
      "Epoch:  52 | Train loss: 0.273 | Val loss: 0.962 | Gen: ehathay ariway ondiycioninway isway orkingway\n",
      "Epoch:  53 | Train loss: 0.330 | Val loss: 1.156 | Gen: eththay ariway ondititiocay isway orkingway\n",
      "Epoch:  54 | Train loss: 0.388 | Val loss: 0.944 | Gen: ethay ariway onditioncinway isway orkingway\n",
      "Epoch:  55 | Train loss: 0.309 | Val loss: 0.916 | Gen: ethay ariway onditionincay isway orkingway\n",
      "Epoch:  56 | Train loss: 0.284 | Val loss: 0.950 | Gen: ehathay ariway onditiongcay isway orkingway\n",
      "Epoch:  57 | Train loss: 0.273 | Val loss: 1.156 | Gen: ehay ariway ondioioincay isway orkingway\n",
      "Epoch:  58 | Train loss: 0.256 | Val loss: 0.904 | Gen: ehathway ariway onditiongcay isway orkingway\n",
      "Epoch:  59 | Train loss: 0.223 | Val loss: 0.860 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  60 | Train loss: 0.210 | Val loss: 0.861 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  61 | Train loss: 0.202 | Val loss: 0.854 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  62 | Train loss: 0.195 | Val loss: 0.857 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  63 | Train loss: 0.190 | Val loss: 0.855 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  64 | Train loss: 0.184 | Val loss: 0.859 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  65 | Train loss: 0.179 | Val loss: 0.856 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  66 | Train loss: 0.175 | Val loss: 0.859 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  67 | Train loss: 0.170 | Val loss: 0.857 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  68 | Train loss: 0.167 | Val loss: 0.862 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  69 | Train loss: 0.162 | Val loss: 0.864 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  70 | Train loss: 0.157 | Val loss: 0.864 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  71 | Train loss: 0.152 | Val loss: 0.871 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  72 | Train loss: 0.148 | Val loss: 0.871 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  73 | Train loss: 0.144 | Val loss: 0.874 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  74 | Train loss: 0.140 | Val loss: 0.878 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  75 | Train loss: 0.136 | Val loss: 0.881 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  76 | Train loss: 0.132 | Val loss: 0.882 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  77 | Train loss: 0.128 | Val loss: 0.887 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  78 | Train loss: 0.125 | Val loss: 0.890 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  79 | Train loss: 0.121 | Val loss: 0.890 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  80 | Train loss: 0.117 | Val loss: 0.894 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  81 | Train loss: 0.114 | Val loss: 0.898 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  82 | Train loss: 0.110 | Val loss: 0.899 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  83 | Train loss: 0.107 | Val loss: 0.907 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  84 | Train loss: 0.104 | Val loss: 0.904 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  85 | Train loss: 0.101 | Val loss: 0.914 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  86 | Train loss: 0.098 | Val loss: 0.913 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  87 | Train loss: 0.094 | Val loss: 0.922 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  88 | Train loss: 0.092 | Val loss: 0.923 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  89 | Train loss: 0.089 | Val loss: 0.927 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  90 | Train loss: 0.086 | Val loss: 0.927 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  91 | Train loss: 0.083 | Val loss: 0.939 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  92 | Train loss: 0.129 | Val loss: 1.462 | Gen: ehay ariraway onditiongciningway isway orkingway\n",
      "Epoch:  93 | Train loss: 0.354 | Val loss: 1.347 | Gen: ethay arway odinquinioncay isway orkingway\n",
      "Epoch:  94 | Train loss: 0.307 | Val loss: 1.076 | Gen: eethay arirway onditioncingcay isway orkingway\n",
      "Epoch:  95 | Train loss: 0.215 | Val loss: 0.909 | Gen: ethay arirway onditiongcay isway orkingway\n",
      "Epoch:  96 | Train loss: 0.166 | Val loss: 0.848 | Gen: ethay ariway onditiongcioncay isway orkingway\n",
      "Epoch:  97 | Train loss: 0.141 | Val loss: 0.863 | Gen: ethay airway onditioncingcay isway orkingway\n",
      "Epoch:  98 | Train loss: 0.125 | Val loss: 0.773 | Gen: ethay ariway onditiongcinay isway orkingway\n",
      "Epoch:  99 | Train loss: 0.117 | Val loss: 0.833 | Gen: ethay ariway onditiongcay isway orkingway\n",
      "Obtained lowest validation loss of: 0.7727413771762734\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay ariway onditiongcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans32_args_s = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True, \n",
    "              'nepochs':100, \n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 100,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 64,\n",
    "              'hidden_size': 32,\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans32_args_s.update(args_dict)\n",
    "print_opts(trans32_args_s)\n",
    "\n",
    "trans32_encoder_s, trans32_decoder_s, trans32_losses_s = train(trans32_args_s)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_s, trans32_decoder_s, None, trans32_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l28mKuZxvaRT",
    "outputId": "d358d69c-392f-436d-f928-6c4fc815d631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay ariway onditiongcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_s, trans32_decoder_s, None, trans32_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L8EqLYFu48H"
   },
   "source": [
    "In the following cells, we investigate the effects of increasing model size and dataset size on the training / validation curves and generalization of the Transformer. We will increase hidden size to 64, and also increase dataset size. Include the best achieved validation loss in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdZO69DozuUu",
    "outputId": "7a74afdb-7cae-4224-e583-6efc9d2b5b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_large                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 100                                    \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 10                                     \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 512                                    \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('blood', 'oodblay')\n",
      "('wen', 'enway')\n",
      "('anthem', 'anthemway')\n",
      "('starch', 'archstay')\n",
      "('homepage', 'omepagehay')\n",
      "Num unique word pairs: 22402\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.719 | Val loss: 2.352 | Gen: onay ay-ay otay -ay o-o-o-oy\n",
      "Epoch:   1 | Train loss: 2.081 | Val loss: 2.098 | Gen: eay away onatay-onay ay onway-way\n",
      "Epoch:   2 | Train loss: 1.860 | Val loss: 1.937 | Gen: eteway awaray ongfay-onay-onay iay onway-way\n",
      "Epoch:   3 | Train loss: 1.718 | Val loss: 1.848 | Gen: eteway awaray ongongay-ongay-onay iay ongway-y-y\n",
      "Epoch:   4 | Train loss: 1.630 | Val loss: 1.794 | Gen: eteway iray ongfingway-ongfay iay ongway-way\n",
      "Epoch:   5 | Train loss: 1.568 | Val loss: 1.893 | Gen: eway iray ongfay-ingay isay ongway\n",
      "Epoch:   6 | Train loss: 1.515 | Val loss: 1.721 | Gen: eway irarway ongway-ingay isay ongway\n",
      "Epoch:   7 | Train loss: 1.427 | Val loss: 1.671 | Gen: eway away ongay-ingay isay ongway\n",
      "Epoch:   8 | Train loss: 1.358 | Val loss: 1.592 | Gen: eteway arway ongongay-y-ingngay isay ongway-y\n",
      "Epoch:   9 | Train loss: 1.294 | Val loss: 1.610 | Gen: eteway arway ongway isay orway\n",
      "Epoch:  10 | Train loss: 1.259 | Val loss: 1.522 | Gen: eteway irarrrrrray otingngnay-ingngiona isay otway-ingway\n",
      "Epoch:  11 | Train loss: 1.201 | Val loss: 1.469 | Gen: eteway away ongongnay-y-angnay isay orway-ingay\n",
      "Epoch:  12 | Train loss: 1.149 | Val loss: 1.498 | Gen: eteway arrrrrray ongonay-ingngngionay isay otwmeray\n",
      "Epoch:  13 | Train loss: 1.117 | Val loss: 1.420 | Gen: eteway awray ongdingnay-y-ay isay orgway\n",
      "Epoch:  14 | Train loss: 1.072 | Val loss: 1.455 | Gen: eteway arrrrrrray otindindindtindway isay otwmingway\n",
      "Epoch:  15 | Train loss: 1.043 | Val loss: 1.377 | Gen: eteway iray ongongngnay isway orgway\n",
      "Epoch:  16 | Train loss: 1.010 | Val loss: 1.354 | Gen: eteway iray ongdinay-y-inginay isay orway\n",
      "Epoch:  17 | Train loss: 0.962 | Val loss: 1.356 | Gen: eteway iray ongngday-y-y-anginay isway orgway\n",
      "Epoch:  18 | Train loss: 0.933 | Val loss: 1.335 | Gen: eteway iray ongoininway-ay isway orwringway\n",
      "Epoch:  19 | Train loss: 0.910 | Val loss: 1.518 | Gen: ethhay iray ongdinay-y-ay isway orgway\n",
      "Epoch:  20 | Train loss: 0.905 | Val loss: 1.274 | Gen: ethay iray ongoinway-y-inionway isway orwringway\n",
      "Epoch:  21 | Train loss: 0.859 | Val loss: 1.451 | Gen: ethay iray ongdinay-inway isway orgray\n",
      "Epoch:  22 | Train loss: 0.848 | Val loss: 1.427 | Gen: ethway iray ongfinway-y-y isway orwringyway\n",
      "Epoch:  23 | Train loss: 0.828 | Val loss: 1.386 | Gen: ethay iray ongdinay-inway isway orgryray\n",
      "Epoch:  24 | Train loss: 0.810 | Val loss: 1.229 | Gen: ethay iray ondingnway-y isway orgwray\n",
      "Epoch:  25 | Train loss: 0.764 | Val loss: 1.307 | Gen: ethay arrray ongoinway-ionway isway orgrinway\n",
      "Epoch:  26 | Train loss: 0.749 | Val loss: 1.099 | Gen: ethay iray ondingntway isway orgray\n",
      "Epoch:  27 | Train loss: 0.723 | Val loss: 1.084 | Gen: ethay iray ondingntinay isway orrkkengay\n",
      "Epoch:  28 | Train loss: 0.706 | Val loss: 1.039 | Gen: ethay arrray ondinintiningcay isway orkkingray\n",
      "Epoch:  29 | Train loss: 0.685 | Val loss: 0.995 | Gen: ethay arrray ondingntinay isway orrkkengay\n",
      "Epoch:  30 | Train loss: 0.662 | Val loss: 1.040 | Gen: eteway arriray ondinintiningcay isway orkkingsway\n",
      "Epoch:  31 | Train loss: 0.654 | Val loss: 0.948 | Gen: ethhay arriray ondingintinay isway orkkengway\n",
      "Epoch:  32 | Train loss: 0.624 | Val loss: 1.060 | Gen: eteway arrway ondingintinay-ionway isway orkkingsway\n",
      "Epoch:  33 | Train loss: 0.631 | Val loss: 1.101 | Gen: etehay irayway ondingintinay-ionway isway orkkingray\n",
      "Epoch:  34 | Train loss: 0.615 | Val loss: 1.015 | Gen: ethay arrway ondingintinay-ionway isway orkkingsway\n",
      "Epoch:  35 | Train loss: 0.590 | Val loss: 0.954 | Gen: ethheway ariray ondingintinay isway orkkengway\n",
      "Epoch:  36 | Train loss: 0.570 | Val loss: 1.053 | Gen: etheway away ondininginay-ionway isway orkingray\n",
      "Epoch:  37 | Train loss: 0.562 | Val loss: 0.868 | Gen: ethay ariray ondingintinay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.550 | Val loss: 0.998 | Gen: etheway ariray ondingintinay isway orkingway\n",
      "Epoch:  39 | Train loss: 0.620 | Val loss: 1.050 | Gen: ethayeay ariray ondingintinay-ionway isway orkkngnway\n",
      "Epoch:  40 | Train loss: 0.565 | Val loss: 0.894 | Gen: ethay arriray ondingintinay isway orkinginway\n",
      "Epoch:  41 | Train loss: 0.508 | Val loss: 0.850 | Gen: etheway away ondidintiningway isway orkingway\n",
      "Epoch:  42 | Train loss: 0.480 | Val loss: 0.803 | Gen: ethay away ondidintiningway isway orkkingway\n",
      "Epoch:  43 | Train loss: 0.458 | Val loss: 0.800 | Gen: ethay away ondigintinay isway orkingway\n",
      "Epoch:  44 | Train loss: 0.444 | Val loss: 0.790 | Gen: ethay away ondigintinay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.432 | Val loss: 0.775 | Gen: ethay away ondigintinay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.423 | Val loss: 0.784 | Gen: ethay away ondigintinay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.419 | Val loss: 0.764 | Gen: ethay away ondigintinay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.403 | Val loss: 0.771 | Gen: ethhay away ondigintinay isway orkingway\n",
      "Epoch:  49 | Train loss: 0.397 | Val loss: 0.773 | Gen: ethay away ondigintinay isway orkingway\n",
      "Epoch:  50 | Train loss: 0.384 | Val loss: 0.749 | Gen: ethay awayway ondigitininay isway orkingway\n",
      "Epoch:  51 | Train loss: 0.376 | Val loss: 0.751 | Gen: ethay awayway ondidintiningay isway orkingway\n",
      "Epoch:  52 | Train loss: 0.366 | Val loss: 0.742 | Gen: ethay awayway onditinginay isway orkingway\n",
      "Epoch:  53 | Train loss: 0.360 | Val loss: 0.761 | Gen: ethay awayway ondidintininway isway orkingway\n",
      "Epoch:  54 | Train loss: 0.364 | Val loss: 0.840 | Gen: ethay awarway ondigitinnay isway orkingway\n",
      "Epoch:  55 | Train loss: 0.383 | Val loss: 1.036 | Gen: ethay awayway ondngintinnnnay isway orkngnnway\n",
      "Epoch:  56 | Train loss: 0.437 | Val loss: 0.856 | Gen: ethebay awayway ondiditininigcay isway orkingrway\n",
      "Epoch:  57 | Train loss: 0.405 | Val loss: 0.795 | Gen: ethay awayway onditinginay isway okwringway\n",
      "Epoch:  58 | Train loss: 0.377 | Val loss: 0.752 | Gen: ethay awayway onditininiongcay isway orkingway\n",
      "Epoch:  59 | Train loss: 0.352 | Val loss: 0.701 | Gen: ethay awaway ondiditininingcay isway orkingway\n",
      "Epoch:  60 | Train loss: 0.320 | Val loss: 0.675 | Gen: ethay awayway ondiditiningay isway orkingway\n",
      "Epoch:  61 | Train loss: 0.303 | Val loss: 0.670 | Gen: ethay awayway ondiditiningay isway orkingway\n",
      "Epoch:  62 | Train loss: 0.293 | Val loss: 0.663 | Gen: ethay awayway ondiditiningay isway orkingway\n",
      "Epoch:  63 | Train loss: 0.285 | Val loss: 0.661 | Gen: ethay awayway ondiditiningay isway orkingway\n",
      "Epoch:  64 | Train loss: 0.277 | Val loss: 0.658 | Gen: ethay awayway onditinginay isway orkingway\n",
      "Epoch:  65 | Train loss: 0.271 | Val loss: 0.655 | Gen: ethay awayway onditinginay isway orkingway\n",
      "Epoch:  66 | Train loss: 0.264 | Val loss: 0.651 | Gen: ethay awayway onditinginay isway orkingway\n",
      "Epoch:  67 | Train loss: 0.257 | Val loss: 0.648 | Gen: ethay awayway onditinginay isway orkingway\n",
      "Epoch:  68 | Train loss: 0.251 | Val loss: 0.641 | Gen: ethay awayway onditinginay isway orkingway\n",
      "Epoch:  69 | Train loss: 0.245 | Val loss: 0.645 | Gen: ethay awayway onditinginay isway orkingway\n",
      "Epoch:  70 | Train loss: 0.242 | Val loss: 0.635 | Gen: ethay awaway onditinginay isway orkingway\n",
      "Epoch:  71 | Train loss: 0.236 | Val loss: 0.644 | Gen: ethay awaway onditinginay isway orkingway\n",
      "Epoch:  72 | Train loss: 0.234 | Val loss: 0.643 | Gen: ethay awaway ondiditininengcay isway orkingway\n",
      "Epoch:  73 | Train loss: 0.232 | Val loss: 0.685 | Gen: ethay awaway onditinginay isway orkingway\n",
      "Epoch:  74 | Train loss: 0.236 | Val loss: 0.670 | Gen: ethay awaway onditininingcay isway orkingway\n",
      "Epoch:  75 | Train loss: 0.299 | Val loss: 1.070 | Gen: ethay awrway onditioningwcay isway orknginwwway\n",
      "Epoch:  76 | Train loss: 0.396 | Val loss: 0.772 | Gen: etheay arirway onditinioningcay isway orkingwnway\n",
      "Epoch:  77 | Train loss: 0.293 | Val loss: 0.661 | Gen: ethay ariway onditinginay isway orkingwnway\n",
      "Epoch:  78 | Train loss: 0.249 | Val loss: 0.611 | Gen: ethay awaway ondiditiningay isway orkingway\n",
      "Epoch:  79 | Train loss: 0.219 | Val loss: 0.577 | Gen: ethay awaway onditinginay isway orkingway\n",
      "Epoch:  80 | Train loss: 0.203 | Val loss: 0.572 | Gen: ethay awaway onditinginay isway orkingway\n",
      "Epoch:  81 | Train loss: 0.196 | Val loss: 0.580 | Gen: ethay awaway onditinginay isway orkingway\n",
      "Epoch:  82 | Train loss: 0.189 | Val loss: 0.576 | Gen: ethay awaway onditinginay isway orkingway\n",
      "Epoch:  83 | Train loss: 0.184 | Val loss: 0.574 | Gen: ethay airway onditinginay isway orkingway\n",
      "Epoch:  84 | Train loss: 0.179 | Val loss: 0.569 | Gen: ethay airway onditinginay isway orkingway\n",
      "Epoch:  85 | Train loss: 0.175 | Val loss: 0.567 | Gen: ethay airway onditiniongcay isway orkingway\n",
      "Epoch:  86 | Train loss: 0.170 | Val loss: 0.563 | Gen: ethay airway onditiniongcay isway orkingway\n",
      "Epoch:  87 | Train loss: 0.167 | Val loss: 0.563 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  88 | Train loss: 0.163 | Val loss: 0.556 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  89 | Train loss: 0.159 | Val loss: 0.557 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  90 | Train loss: 0.155 | Val loss: 0.552 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  91 | Train loss: 0.152 | Val loss: 0.558 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  92 | Train loss: 0.149 | Val loss: 0.549 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  93 | Train loss: 0.146 | Val loss: 0.548 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  94 | Train loss: 0.142 | Val loss: 0.556 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  95 | Train loss: 0.142 | Val loss: 0.577 | Gen: ethay airway onditiningcay isway orkingway\n",
      "Epoch:  96 | Train loss: 0.138 | Val loss: 0.540 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  97 | Train loss: 0.134 | Val loss: 0.545 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  98 | Train loss: 0.130 | Val loss: 0.545 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Epoch:  99 | Train loss: 0.128 | Val loss: 0.536 | Gen: ethay airway onditininingcay isway orkingway\n",
      "Obtained lowest validation loss of: 0.5357620740878499\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditininingcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans32_args_l = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_large', # Increased data set size\n",
    "              'cuda':True, \n",
    "              'nepochs':100,\n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 10,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 512,\n",
    "              'hidden_size': 32,\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans32_args_l.update(args_dict)\n",
    "print_opts(trans32_args_l)\n",
    "\n",
    "trans32_encoder_l, trans32_decoder_l, trans32_losses_l = train(trans32_args_l)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_l, trans32_decoder_l, None, trans32_args_l)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmoTgrDcr_dw",
    "outputId": "b3393377-e2a5-4116-f65d-0644a07b396e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 20                                     \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 64                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('impartiality', 'impartialityway')\n",
      "('bind', 'indbay')\n",
      "('follow', 'ollowfay')\n",
      "('piquet', 'iquetpay')\n",
      "('undressed', 'undressedway')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.483 | Val loss: 2.064 | Gen: ay away onay isssssssssssssssssss oray\n",
      "Epoch:   1 | Train loss: 1.722 | Val loss: 1.755 | Gen: eay away ingngingnay isway ongway-ongway\n",
      "Epoch:   2 | Train loss: 1.435 | Val loss: 1.590 | Gen: eay away ongingingay-ongngay- isway ongray-ongway\n",
      "Epoch:   3 | Train loss: 1.231 | Val loss: 1.530 | Gen: eththay arway ongay-inay-inay isway onray-ingway\n",
      "Epoch:   4 | Train loss: 1.090 | Val loss: 1.454 | Gen: eayhay rrway onditingindindindidi isway onringway-ingway\n",
      "Epoch:   5 | Train loss: 0.999 | Val loss: 1.355 | Gen: ethay irway onciningayionay isway orwingway-ay\n",
      "Epoch:   6 | Train loss: 0.844 | Val loss: 1.180 | Gen: ethay arrway oncingincincay isway orwingway-ingway\n",
      "Epoch:   7 | Train loss: 0.713 | Val loss: 1.116 | Gen: ethay arway onciinginay isway orwingway\n",
      "Epoch:   8 | Train loss: 0.635 | Val loss: 1.068 | Gen: ethay arrway onciningtincay isway orwingway\n",
      "Epoch:   9 | Train loss: 0.554 | Val loss: 0.947 | Gen: ehay arway ondiiningcay isway orwingway\n",
      "Epoch:  10 | Train loss: 0.494 | Val loss: 0.958 | Gen: ehthay arrway onditingcationnncay isway orkingway\n",
      "Epoch:  11 | Train loss: 0.470 | Val loss: 0.995 | Gen: ethay arway onditiongiongcationg iisway orkingway\n",
      "Epoch:  12 | Train loss: 0.391 | Val loss: 0.866 | Gen: ehthay arway ondiitingionay isway orkingway\n",
      "Epoch:  13 | Train loss: 0.321 | Val loss: 0.845 | Gen: ethay arrway onditionioniongionat isway okrgwingway\n",
      "Epoch:  14 | Train loss: 0.284 | Val loss: 0.853 | Gen: ethay arway onditiningcay isway owrkingway\n",
      "Epoch:  15 | Train loss: 0.253 | Val loss: 0.813 | Gen: ethay arrway onditionioniongway isway owrkingway\n",
      "Epoch:  16 | Train loss: 0.248 | Val loss: 0.839 | Gen: ethay arrway onditioniniongcay isway orkingway\n",
      "Epoch:  17 | Train loss: 0.245 | Val loss: 0.929 | Gen: ethay away onditioniincay isay owwringway\n",
      "Epoch:  18 | Train loss: 0.237 | Val loss: 0.774 | Gen: ethay arway onditionioniongway isway orkingway\n",
      "Epoch:  19 | Train loss: 0.197 | Val loss: 0.744 | Gen: etetay arway onditiongioncay isway orkingway\n",
      "Epoch:  20 | Train loss: 0.184 | Val loss: 0.633 | Gen: etay arway onditioniongcay isway orkingway\n",
      "Epoch:  21 | Train loss: 0.136 | Val loss: 0.611 | Gen: ethay arway onditioniongcay isway orkingwwway\n",
      "Epoch:  22 | Train loss: 0.111 | Val loss: 0.616 | Gen: ettay arway onditioniongcay isway orkingway\n",
      "Epoch:  23 | Train loss: 0.099 | Val loss: 0.632 | Gen: ethay arway onditionioncay isway orkingway\n",
      "Epoch:  24 | Train loss: 0.090 | Val loss: 0.564 | Gen: ethay arway onditionioniongay isway orkingway\n",
      "Epoch:  25 | Train loss: 0.070 | Val loss: 0.617 | Gen: ethay arway onditioniongcay isway orkingway\n",
      "Epoch:  26 | Train loss: 0.063 | Val loss: 0.605 | Gen: ethay arway onditiniongcay isway orkingway\n",
      "Epoch:  27 | Train loss: 0.054 | Val loss: 0.572 | Gen: ethay arway onditionioncay isway orkingway\n",
      "Epoch:  28 | Train loss: 0.047 | Val loss: 0.588 | Gen: ethay arway onditioniongcay isway orkingway\n",
      "Epoch:  29 | Train loss: 0.094 | Val loss: 1.252 | Gen: eay airway onditinioningway isway oorngwwwwway\n",
      "Epoch:  30 | Train loss: 0.267 | Val loss: 1.084 | Gen: eethay awaray ononitioningcay iisway ooorngway\n",
      "Epoch:  31 | Train loss: 0.262 | Val loss: 0.821 | Gen: ethay awayway onditionionway isway orkingway\n",
      "Epoch:  32 | Train loss: 0.173 | Val loss: 0.607 | Gen: ehay away onditioniongcay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.103 | Val loss: 0.554 | Gen: ethay arway onditioniongay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.082 | Val loss: 0.627 | Gen: ethay arway onditiningway isway orkingway\n",
      "Epoch:  35 | Train loss: 0.078 | Val loss: 0.582 | Gen: eethay arway onditioniongway isway orkingway\n",
      "Epoch:  36 | Train loss: 0.075 | Val loss: 0.576 | Gen: ethay arway onditioningway isway orkingway\n",
      "Epoch:  37 | Train loss: 0.071 | Val loss: 0.582 | Gen: ethay arway onditioniongcay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.052 | Val loss: 0.510 | Gen: ethay arway onditioniongway isway orkingway\n",
      "Epoch:  39 | Train loss: 0.037 | Val loss: 0.485 | Gen: ethay arway onditioniongway isway orkingway\n",
      "Epoch:  40 | Train loss: 0.029 | Val loss: 0.515 | Gen: ethay arway onditioningway isway orkingway\n",
      "Epoch:  41 | Train loss: 0.024 | Val loss: 0.490 | Gen: ethay arway onditioniongway isway orkingway\n",
      "Epoch:  42 | Train loss: 0.019 | Val loss: 0.521 | Gen: ethay arway onditioningcay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.016 | Val loss: 0.473 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  44 | Train loss: 0.014 | Val loss: 0.481 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.011 | Val loss: 0.480 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.009 | Val loss: 0.478 | Gen: ethay airway onditioniongcay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.008 | Val loss: 0.486 | Gen: ethay airway onditioniongcay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.008 | Val loss: 0.488 | Gen: ethay airwway onditioniongcay isway orkingway\n",
      "Epoch:  49 | Train loss: 0.006 | Val loss: 0.490 | Gen: ethay airway onditioniongcay isway orkingway\n",
      "Obtained lowest validation loss of: 0.47332691343589905\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditioniongcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans64_args_s = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True, \n",
    "              'nepochs':50, \n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 20,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 64, \n",
    "              'hidden_size': 64, # Increased model size\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans64_args_s.update(args_dict)\n",
    "print_opts(trans64_args_s)\n",
    "\n",
    "trans64_encoder_s, trans64_decoder_s, trans64_losses_s = train(trans64_args_s)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans64_encoder_s, trans64_decoder_s, None, trans64_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dardK4RWvUWV",
    "outputId": "277515bd-b56f-47c2-cdd1-3d616d29f7d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_large                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 20                                     \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 512                                    \n",
      "                            hidden_size: 64                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('blood', 'oodblay')\n",
      "('wen', 'enway')\n",
      "('anthem', 'anthemway')\n",
      "('starch', 'archstay')\n",
      "('homepage', 'omepagehay')\n",
      "Num unique word pairs: 22402\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.348 | Val loss: 2.101 | Gen: eray ay-ay-ay-ay ininay-inayday i-------ay onay-ay-ay\n",
      "Epoch:   1 | Train loss: 1.599 | Val loss: 1.755 | Gen: etay away-iay ongingingay-ingay isay ongay-ongay\n",
      "Epoch:   2 | Train loss: 1.346 | Val loss: 1.712 | Gen: etetehay away ontay-indway isway onmway\n",
      "Epoch:   3 | Train loss: 1.210 | Val loss: 1.622 | Gen: hethay away-iarararay oningway-ingngngway isay ongray-ingngngway\n",
      "Epoch:   4 | Train loss: 1.067 | Val loss: 1.531 | Gen: etay iray oningdingngngngngngn isway orongngngngngngngngn\n",
      "Epoch:   5 | Train loss: 0.928 | Val loss: 1.292 | Gen: ethay awayiayway oonioncioniongay iiay oorongway\n",
      "Epoch:   6 | Train loss: 0.810 | Val loss: 1.167 | Gen: etay away onicigingingway iisay owingway\n",
      "Epoch:   7 | Train loss: 0.719 | Val loss: 1.214 | Gen: ethay irarway oniditiongiongay isway orkingway\n",
      "Epoch:   8 | Train loss: 0.672 | Val loss: 1.257 | Gen: ethay ariway ondiniongingway isway oningway\n",
      "Epoch:   9 | Train loss: 0.623 | Val loss: 1.171 | Gen: ehay ariway onditioniongititay isway owinmingway\n",
      "Epoch:  10 | Train loss: 0.566 | Val loss: 0.855 | Gen: ethway away onditiongingcay isway owingmgngway\n",
      "Epoch:  11 | Train loss: 0.482 | Val loss: 0.803 | Gen: ethway ariway onditiongingcay isway orkingway\n",
      "Epoch:  12 | Train loss: 0.416 | Val loss: 0.855 | Gen: ethehay away onditiongcay isway owkgngway\n",
      "Epoch:  13 | Train loss: 0.412 | Val loss: 0.906 | Gen: ethay away onditionginicay isway owkgingway\n",
      "Epoch:  14 | Train loss: 0.368 | Val loss: 0.709 | Gen: ethway airway onditiongincay isway owingway\n",
      "Epoch:  15 | Train loss: 0.322 | Val loss: 0.635 | Gen: ethay away onditiongingcay isway owkingway\n",
      "Epoch:  16 | Train loss: 0.282 | Val loss: 0.623 | Gen: ethay ariwawawawawawaway onditiongincay isway orkwingway\n",
      "Epoch:  17 | Train loss: 0.248 | Val loss: 0.585 | Gen: ethay away onditioncingcay isway owkingway\n",
      "Epoch:  18 | Train loss: 0.245 | Val loss: 0.440 | Gen: ethay airway onditiongincay isway orkingway\n",
      "Epoch:  19 | Train loss: 0.220 | Val loss: 0.534 | Gen: ethay awaway ondititingincay isway owkingway\n",
      "Epoch:  20 | Train loss: 0.208 | Val loss: 0.544 | Gen: ethay airway onditioningincay isway orkingway\n",
      "Epoch:  21 | Train loss: 0.184 | Val loss: 0.482 | Gen: ethay airway ondititionginay isway orkingway\n",
      "Epoch:  22 | Train loss: 0.161 | Val loss: 0.753 | Gen: ethay airway onditioningicay iisway owkingway\n",
      "Epoch:  23 | Train loss: 0.190 | Val loss: 0.527 | Gen: ethay airway onditioingincccay isway orkingway\n",
      "Epoch:  24 | Train loss: 0.207 | Val loss: 1.040 | Gen: ethay airway ononiteongicigiay isway oorkingway\n",
      "Epoch:  25 | Train loss: 0.266 | Val loss: 0.463 | Gen: ethay away onditioncingcay isway orkingway\n",
      "Epoch:  26 | Train loss: 0.174 | Val loss: 0.454 | Gen: ethay airway onditionningcay isway orkingway\n",
      "Epoch:  27 | Train loss: 0.212 | Val loss: 0.377 | Gen: ethay airway onditiongincccay isway orkingway\n",
      "Epoch:  28 | Train loss: 0.116 | Val loss: 0.311 | Gen: ethay airway onditiongincccay isway orkingway\n",
      "Epoch:  29 | Train loss: 0.094 | Val loss: 0.264 | Gen: ethay airway onditionginccay isway orkingway\n",
      "Epoch:  30 | Train loss: 0.079 | Val loss: 0.252 | Gen: ethay airway onditionnginccay isway orkingway\n",
      "Epoch:  31 | Train loss: 0.075 | Val loss: 0.234 | Gen: ethay airway onditionginccay isway orkingway\n",
      "Epoch:  32 | Train loss: 0.065 | Val loss: 0.227 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.062 | Val loss: 0.231 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.061 | Val loss: 0.237 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  35 | Train loss: 0.053 | Val loss: 0.207 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  36 | Train loss: 0.046 | Val loss: 0.202 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  37 | Train loss: 0.040 | Val loss: 0.190 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.036 | Val loss: 0.195 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  39 | Train loss: 0.032 | Val loss: 0.192 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  40 | Train loss: 0.028 | Val loss: 0.186 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.026 | Val loss: 0.183 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  42 | Train loss: 0.024 | Val loss: 0.178 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.021 | Val loss: 0.179 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  44 | Train loss: 0.020 | Val loss: 0.178 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.018 | Val loss: 0.179 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.017 | Val loss: 0.179 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.015 | Val loss: 0.183 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.014 | Val loss: 0.181 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  49 | Train loss: 0.013 | Val loss: 0.185 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Obtained lowest validation loss of: 0.17789271136862225\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditioningcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans64_args_l = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_large', # Increased data set size\n",
    "              'cuda':True, \n",
    "              'nepochs':50,\n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 20,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 512, \n",
    "              'hidden_size': 64, # Increased model size\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans64_args_l.update(args_dict)\n",
    "print_opts(trans64_args_l)\n",
    "\n",
    "trans64_encoder_l, trans64_decoder_l, trans64_losses_l = train(trans64_args_l)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans64_encoder_l, trans64_decoder_l, None, trans64_args_l)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSSyiG39vVlN"
   },
   "source": [
    "The following cell generates two loss plots. In the first plot, we compare the effects of increasing dataset size. In the second plot, we compare the effects of increasing model size. Include both plots in your report, and include your analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "-Ql0pxrEvVP6",
    "outputId": "4ae92cba-63d2-4aba-f06a-ee87c230c2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_loss_comparison_by_dataset(trans32_losses_s, trans32_losses_l, trans64_losses_s, trans64_losses_l, trans32_args_s, trans32_args_l, trans64_args_s, trans64_args_l, 'trans_by_dataset')\n",
    "save_loss_comparison_by_hidden(trans32_losses_s, trans32_losses_l, trans64_losses_s, trans64_losses_l, trans32_args_s, trans32_args_l, trans64_args_s, trans64_args_l, 'trans_by_hidden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBnBXRG8mvcn"
   },
   "source": [
    "# Optional: Attention Visualizations\n",
    "\n",
    "One of the benefits of using attention is that it allows us to gain insight into the inner workings of the model.\n",
    "\n",
    "By visualizing the attention weights generated for the input tokens in each decoder step, we can see where the model focuses while producing each output token.\n",
    "\n",
    "The code in this section loads the model you trained from the previous section and uses it to translate a given set of words: it prints the translations and display heatmaps to show how attention is used at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqEC0vN9mvpV"
   },
   "source": [
    "## Step 1: Visualize Attention Masks\n",
    "Play around with visualizing attention maps generated by the previous two models you've trained. Inspect visualizations in one success and one failure case for both models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dkfz-u-MtudL"
   },
   "outputs": [],
   "source": [
    "TEST_WORD_ATTN = 'street'\n",
    "visualize_attention(TEST_WORD_ATTN, rnn_attn_encoder, rnn_attn_decoder, None, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ssa7g35zt2yj"
   },
   "outputs": [],
   "source": [
    "TEST_WORD_ATTN = 'street'\n",
    "visualize_attention(TEST_WORD_ATTN, transformer_encoder, transformer_decoder, None, args, )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4BIpGwANoQOg",
    "pbvpn4MaV0I1",
    "bRWfRdmVVjUl",
    "0yh08KhgnA30",
    "ecEq4TP2lZ4Z",
    "RWwA6OGqlaTq",
    "AJSafHSAmu_w",
    "73_p8d5EmvOJ",
    "vYPae08Io1Fi",
    "9tcpUFKqo2Oi",
    "z1hDi020rT36",
    "MBnBXRG8mvcn"
   ],
   "name": "Copy of nmt.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
